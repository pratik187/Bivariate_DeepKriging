{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1963eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization,Input\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers,initializers\n",
    "from keras.layers import GaussianNoise\n",
    "import keras.backend as Kb\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "# Library for Gaussian process\n",
    "# import GPy\n",
    "##Library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib;matplotlib.rcParams['figure.figsize'] = (8,6)\n",
    "import pylab \n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9cdb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_loc = pd.read_csv(\"../DeepKriging_github_upload/2D_biv_matern_1200.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82620e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# N = len(df_loc)\n",
    "# s = np.vstack((df_loc[\"x\"],df_loc[\"y\"])).T\n",
    "\n",
    "# ## Tukey GH \n",
    "# # g = 1\n",
    "# # h = 3\n",
    "# g = 2\n",
    "# h = 3\n",
    "# # tukey_var1 = []\n",
    "# # tukey_var2 = []\n",
    "# # for i in range(len(df_z1)):\n",
    "# #     tukey_var1.append(((exp(g*df_z1[\"var1\"][i])-1)/g) * exp(h*(df_z1[\"var1\"][i]**2)/2))\n",
    "# #     tukey_var2.append(((exp(g*df_z2[\"var2\"][i])-1)/g) * exp(h*(df_z2[\"var2\"][i]**2)/2))\n",
    "# tukey_var1 = ((exp(g*df_loc[\"var1\"])-1)/g) * exp(h*(df_loc[\"var1\"]**2)/2)\n",
    "# # g = 0.6\n",
    "# # h = 1\n",
    "\n",
    "# g = -0.1\n",
    "# h = 1.3\n",
    "# tukey_var2 = ((exp(g*df_loc[\"var2\"])-1)/g) * exp(h*(df_loc[\"var2\"]**2)/2)\n",
    "# df_var = pd.concat([tukey_var1,tukey_var2], axis = 1)\n",
    "\n",
    "\n",
    "# y = np.array(df_var)\n",
    "\n",
    "\n",
    "# ### Basis functions\n",
    "# df_loc = pd.DataFrame(s,columns = [\"x\",\"y\"])\n",
    "# df_val = pd.DataFrame(y, columns = [\"var1\",\"var2\"])\n",
    "# df = pd.concat([df_loc,df_val], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc98bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../synthetic_data_simulations/2d_biv_nongaussian_1200_1.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"../synthetic_data_simulations/2d_biv_nongaussian_1200_\"+str(1)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0b612",
   "metadata": {},
   "source": [
    "## Replicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf0b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for calculation of MSE and MAE\n",
    "def mse(y_pred,y_true):\n",
    "    mse = np.mean((y_pred-y_true)**2)\n",
    "    return mse\n",
    "\n",
    "def mae(y_pred,y_true):\n",
    "    mae = np.mean(np.absolute(y_pred-y_true))\n",
    "    return mae\n",
    "\n",
    "mse_var1 = []\n",
    "mse_var2 = []\n",
    "for i in range(50):\n",
    "    df_loc = pd.read_csv(\"../synthetic_data_simulations/2d_nongaussian_1200_\"+str(i+1)+\".csv\", sep = \",\")\n",
    "    \n",
    "    variance_var1 = np.var(df_loc[\"var1\"])\n",
    "    variance_var2 = np.var(df_loc[\"var2\"])\n",
    "\n",
    "\n",
    "    def custom_mse(y_true, y_pred):\n",
    "\n",
    "        # calculating squared difference between target and predicted values \n",
    "        loss = Kb.square(y_pred - y_true)  # (batch_size, 2)\n",
    "\n",
    "        # multiplying the values with weights along batch dimension\n",
    "        loss = loss * [(1/variance_var1), (1/variance_var2)]          # (batch_size, 2)\n",
    "\n",
    "        # summing both loss values along batch dimension \n",
    "        loss = Kb.sum(loss, axis=1)        # (batch_size,)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    N = len(df_loc)\n",
    "    s = np.vstack((df_loc[\"x\"],df_loc[\"y\"])).T\n",
    "    y = np.array(df_loc[[\"var1\",\"var2\"]])\n",
    "    num_basis = [2**2,5**2,9**2]\n",
    "    knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "    #knots_1d = [np.linspace(0,1,i) for i in num_basis]\n",
    "    ##Wendland kernel\n",
    "    K = 0\n",
    "    phi = np.zeros((N, sum(num_basis)))\n",
    "    for res in range(len(num_basis)):\n",
    "        theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "        knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "        knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "        for i in range(num_basis[res]):\n",
    "            d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "            for j in range(len(d)):\n",
    "                if d[j] >= 0 and d[j] <= 1:\n",
    "                    phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "                else:\n",
    "                    phi[j,i + K] = 0\n",
    "        K = K + num_basis[res]\n",
    "    s_train, s_test, encoder_train, encoder_test    , y_train, y_test= train_test_split(s, phi, y, \n",
    "                                                                                    test_size=0.3333)\n",
    "    N_train = s_train.shape[0]\n",
    "    N_test = s_test.shape[0]\n",
    "\n",
    "    \n",
    "    # DeepKriging model for continuous data\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(100, input_dim = 2,  kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(100, input_dim = encoder_train.shape[1],  \n",
    "                kernel_initializer=initializers.RandomNormal(stddev=0.01), activation='relu'))\n",
    "#     model.add(Dense(100, input_dim = encoder_train.shape[1],  kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(Dropout(rate=0.5))\n",
    "    # model.add(BatchNormalization())\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "                bias_regularizer=regularizers.l2(1e-4),\n",
    "                activity_regularizer=regularizers.l2(1e-5),activation='relu'))\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    NB_START_EPOCHS = 50 \n",
    "    # NB_START_EPOCHS = 200  # Number of epochs we usually start to train with\n",
    "    BATCH_SIZE = 64  \n",
    "    fold_no = 1\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss= custom_mse, metrics=['mae','mse'])\n",
    "\n",
    "    result = model.fit(encoder_train, y_train, \n",
    "                       validation_data=(encoder_test,y_test), epochs = 300, batch_size = 64, verbose = 2)\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=40),\n",
    "                 ModelCheckpoint(filepath='Biv_nonStationary_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "    result = model.fit(encoder_train, y_train, callbacks=callbacks, \n",
    "                       validation_data=(encoder_test,y_test), epochs = 250, batch_size = 64, verbose = 2)\n",
    "    model = keras.models.load_model('Biv_nonStationary_model.h5', custom_objects={'custom_mse':custom_mse})\n",
    "    y_pred = model.predict(encoder_test)\n",
    "\n",
    "\n",
    "    # Mean Squared Error\n",
    "    mse_var1.append(mse(y_pred[:,0], y_test[:,0]))\n",
    "    mse_var2.append(mse(y_pred[:,1], y_test[:,1]))\n",
    "    \n",
    "# end_time = time.time()\n",
    "# print(\"%s seconds\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afef8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_var1_old = mse_var1.copy()\n",
    "mse_var2_old = mse_var2.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b9b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_var2_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132ba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694ecb37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"mean var 1 : \",np.mean(mse_var1))\n",
    "print(\"mean var 2 : \",np.mean(mse_var2))\n",
    "print(\"variance var 1 : \",np.var(mse_var1))\n",
    "print(\"variance var 2 : \",np.var(mse_var2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21a3e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mse = pd.DataFrame(np.vstack((mse_var1,mse_var2)).T, columns = [\"mse_var1\",\"mse_var2\"])\n",
    "\n",
    "df_mse.to_csv(\"../plot_results/DeepKriging_nongaussian_mse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd6f7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../test_data_nongaussian.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "579c9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = np.vstack((df[\"x\"],df[\"y\"])).T\n",
    "# N = 120\n",
    "# num_basis = [2**2,5**2,9**2]\n",
    "# # num_basis = [2**2,5**2,9**2]\n",
    "# knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "# #knots_1d = [np.linspace(0,1,i) for i in num_basis]\n",
    "# ##Wendland kernel\n",
    "# K = 0\n",
    "# phi = np.zeros((N, sum(num_basis)))\n",
    "# for res in range(len(num_basis)):\n",
    "#     theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "#     knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "#     knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "#     for i in range(num_basis[res]):\n",
    "#         d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "#         for j in range(len(d)):\n",
    "#             if d[j] >= 0 and d[j] <= 1:\n",
    "#                 phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "#             else:\n",
    "#                 phi[j,i + K] = 0\n",
    "#     K = K + num_basis[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0e75611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val = np.array(df[[\"var1\",\"var2\"]])\n",
    "# y_pred = model.predict(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0297188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8056064651083383\n",
      "1.575428454163753\n"
     ]
    }
   ],
   "source": [
    "# print(mae(y_pred[:,0], y_val[:,0]))\n",
    "# print(mae(y_pred[:,1], y_val[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d251ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred = pd.DataFrame(y_pred, columns = [\"var1\",\"var2\"])\n",
    "# df_pred.to_csv(\"../nongaussian_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce0a3b",
   "metadata": {},
   "source": [
    "## Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42616836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_loc = pd.DataFrame(s,columns = [\"x\",\"y\"])\n",
    "# df_val = pd.DataFrame(y, columns = [\"var1\",\"var2\"])\n",
    "# df = pd.concat([df_loc,df_val], axis = 1)\n",
    "# df.to_csv(\"../synthetic_datasets/2d_biv_nongaussian_1200_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a221e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
