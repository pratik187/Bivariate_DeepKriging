{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79768a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization,Input\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "# Library for Gaussian process\n",
    "# import GPy\n",
    "##Library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib;matplotlib.rcParams['figure.figsize'] = (8,6)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebd93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = pd.read_csv(\"../synthetic_data_simulations/2d_biv_nonStationary_1200.csv\", sep = \",\")\n",
    "N = len(df_loc)\n",
    "\n",
    "s = np.vstack((df_loc[\"x\"],df_loc[\"y\"])).T\n",
    "y = np.array(df_loc[[\"var1\",\"var2\"]])\n",
    "### Basis functions\n",
    "\n",
    "num_basis = [2**2,5**2,9**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "#knots_1d = [np.linspace(0,1,i) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + K] = 0\n",
    "    K = K + num_basis[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137e7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model layers \n",
    "\n",
    "input_dim = Input(shape = (phi.shape[1], ))\n",
    "layer1 = Dense(100, kernel_initializer='he_uniform', activation = 'relu')(input_dim)\n",
    "layer2 = Dense(100, activation = 'relu')(layer1)\n",
    "layer3 = Dense(100, activation = 'relu')(layer2)\n",
    "layer4 = Dense(50, activation = 'relu')(layer3)\n",
    "layer5 = Dense(50, activation = 'relu')(layer4)\n",
    "final_layer = Dense(2, activation = 'linear')(layer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36e0e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2)\n",
      "(768, 2)\n"
     ]
    }
   ],
   "source": [
    "s_train, s_test, encoder_train, encoder_test    , y_train, y_test= train_test_split(s, phi, y, \n",
    "                                                                                    test_size=0.2)\n",
    "print(s_test.shape)\n",
    "s_train_ensemble, s_train_mse, X_train_ensemble, X_train_mse, y_train_ensemble, y_train_mse= train_test_split(s_train, encoder_train, y_train, test_size=0.2)\n",
    "print(s_train_ensemble.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380ee874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 2)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 110)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               11100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 39,002\n",
      "Trainable params: 39,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "9/9 - 3s - loss: 0.2672 - val_loss: 0.1162\n",
      "Epoch 2/400\n",
      "9/9 - 0s - loss: 0.1056 - val_loss: 0.0748\n",
      "Epoch 3/400\n",
      "9/9 - 0s - loss: 0.0639 - val_loss: 0.0453\n",
      "Epoch 4/400\n",
      "9/9 - 0s - loss: 0.0431 - val_loss: 0.0528\n",
      "Epoch 5/400\n",
      "9/9 - 0s - loss: 0.0349 - val_loss: 0.0436\n",
      "Epoch 6/400\n",
      "9/9 - 0s - loss: 0.0259 - val_loss: 0.0462\n",
      "Epoch 7/400\n",
      "9/9 - 0s - loss: 0.0195 - val_loss: 0.0665\n",
      "Epoch 8/400\n",
      "9/9 - 0s - loss: 0.0160 - val_loss: 0.0562\n",
      "Epoch 9/400\n",
      "9/9 - 0s - loss: 0.0125 - val_loss: 0.0734\n",
      "Epoch 10/400\n",
      "9/9 - 0s - loss: 0.0115 - val_loss: 0.0734\n",
      "Epoch 11/400\n",
      "9/9 - 0s - loss: 0.0094 - val_loss: 0.0774\n",
      "Epoch 12/400\n",
      "9/9 - 0s - loss: 0.0079 - val_loss: 0.0682\n",
      "Epoch 13/400\n",
      "9/9 - 0s - loss: 0.0057 - val_loss: 0.0797\n",
      "Epoch 14/400\n",
      "9/9 - 0s - loss: 0.0041 - val_loss: 0.0791\n",
      "Epoch 15/400\n",
      "9/9 - 0s - loss: 0.0026 - val_loss: 0.0899\n",
      "Epoch 16/400\n",
      "9/9 - 0s - loss: 0.0020 - val_loss: 0.0873\n",
      "Epoch 17/400\n",
      "9/9 - 0s - loss: 0.0018 - val_loss: 0.0901\n",
      "Epoch 18/400\n",
      "9/9 - 0s - loss: 0.0019 - val_loss: 0.0843\n",
      "Epoch 19/400\n",
      "9/9 - 0s - loss: 0.0014 - val_loss: 0.0825\n",
      "Epoch 20/400\n",
      "9/9 - 0s - loss: 0.0010 - val_loss: 0.0767\n",
      "Epoch 21/400\n",
      "9/9 - 0s - loss: 0.0010 - val_loss: 0.0867\n",
      "Epoch 22/400\n",
      "9/9 - 0s - loss: 8.7002e-04 - val_loss: 0.0829\n",
      "Epoch 23/400\n",
      "9/9 - 0s - loss: 8.8176e-04 - val_loss: 0.0809\n",
      "Epoch 24/400\n",
      "9/9 - 0s - loss: 9.9888e-04 - val_loss: 0.0771\n",
      "Epoch 25/400\n",
      "9/9 - 0s - loss: 0.0016 - val_loss: 0.0919\n",
      "Epoch 26/400\n",
      "9/9 - 0s - loss: 0.0016 - val_loss: 0.0752\n",
      "Epoch 27/400\n",
      "9/9 - 0s - loss: 0.0013 - val_loss: 0.0780\n",
      "Epoch 28/400\n",
      "9/9 - 0s - loss: 0.0015 - val_loss: 0.0703\n",
      "Epoch 29/400\n",
      "9/9 - 0s - loss: 0.0016 - val_loss: 0.0747\n",
      "Epoch 30/400\n",
      "9/9 - 0s - loss: 0.0016 - val_loss: 0.0859\n",
      "Epoch 31/400\n",
      "9/9 - 0s - loss: 0.0013 - val_loss: 0.0841\n",
      "Epoch 32/400\n",
      "9/9 - 0s - loss: 0.0012 - val_loss: 0.0756\n",
      "Epoch 33/400\n",
      "9/9 - 0s - loss: 7.7364e-04 - val_loss: 0.0768\n",
      "Epoch 34/400\n",
      "9/9 - 0s - loss: 6.0942e-04 - val_loss: 0.0742\n",
      "Epoch 35/400\n",
      "9/9 - 0s - loss: 4.9339e-04 - val_loss: 0.0778\n",
      "Epoch 36/400\n",
      "9/9 - 0s - loss: 5.1180e-04 - val_loss: 0.0768\n",
      "Epoch 37/400\n",
      "9/9 - 0s - loss: 4.7399e-04 - val_loss: 0.0784\n",
      "Epoch 38/400\n",
      "9/9 - 0s - loss: 5.0456e-04 - val_loss: 0.0726\n",
      "Epoch 39/400\n",
      "9/9 - 0s - loss: 5.0560e-04 - val_loss: 0.0740\n",
      "Epoch 40/400\n",
      "9/9 - 0s - loss: 4.2770e-04 - val_loss: 0.0753\n",
      "Epoch 41/400\n",
      "9/9 - 0s - loss: 5.1917e-04 - val_loss: 0.0767\n",
      "Epoch 42/400\n",
      "9/9 - 0s - loss: 5.1049e-04 - val_loss: 0.0733\n",
      "Epoch 43/400\n",
      "9/9 - 0s - loss: 5.4019e-04 - val_loss: 0.0746\n",
      "Epoch 44/400\n",
      "9/9 - 0s - loss: 0.0010 - val_loss: 0.0811\n",
      "Epoch 45/400\n",
      "9/9 - 0s - loss: 0.0019 - val_loss: 0.0653\n",
      "Epoch 46/400\n",
      "9/9 - 0s - loss: 0.0019 - val_loss: 0.0795\n",
      "Epoch 47/400\n",
      "9/9 - 0s - loss: 0.0024 - val_loss: 0.0730\n",
      "Epoch 48/400\n",
      "9/9 - 0s - loss: 0.0035 - val_loss: 0.1011\n",
      "Epoch 49/400\n",
      "9/9 - 0s - loss: 0.0040 - val_loss: 0.0698\n",
      "Epoch 50/400\n",
      "9/9 - 0s - loss: 0.0048 - val_loss: 0.0854\n",
      "Epoch 51/400\n",
      "9/9 - 0s - loss: 0.0051 - val_loss: 0.0683\n",
      "Epoch 52/400\n",
      "9/9 - 0s - loss: 0.0053 - val_loss: 0.0833\n",
      "Epoch 53/400\n",
      "9/9 - 0s - loss: 0.0059 - val_loss: 0.0641\n",
      "Epoch 54/400\n",
      "9/9 - 0s - loss: 0.0054 - val_loss: 0.0846\n",
      "Epoch 55/400\n",
      "9/9 - 0s - loss: 0.0042 - val_loss: 0.0739\n",
      "Epoch 56/400\n",
      "9/9 - 0s - loss: 0.0031 - val_loss: 0.0755\n",
      "Epoch 57/400\n",
      "9/9 - 0s - loss: 0.0025 - val_loss: 0.0813\n",
      "Epoch 58/400\n",
      "9/9 - 0s - loss: 0.0025 - val_loss: 0.0800\n",
      "Epoch 59/400\n",
      "9/9 - 0s - loss: 0.0024 - val_loss: 0.0835\n",
      "Epoch 60/400\n",
      "9/9 - 0s - loss: 0.0019 - val_loss: 0.0790\n",
      "Epoch 61/400\n",
      "9/9 - 0s - loss: 0.0016 - val_loss: 0.0860\n",
      "Epoch 62/400\n",
      "9/9 - 0s - loss: 0.0014 - val_loss: 0.0815\n",
      "Epoch 63/400\n",
      "9/9 - 0s - loss: 9.6069e-04 - val_loss: 0.0788\n",
      "Epoch 64/400\n",
      "9/9 - 0s - loss: 7.7411e-04 - val_loss: 0.0755\n",
      "Epoch 65/400\n",
      "9/9 - 0s - loss: 9.7788e-04 - val_loss: 0.0733\n",
      "Epoch 66/400\n",
      "9/9 - 0s - loss: 7.5992e-04 - val_loss: 0.0744\n",
      "Epoch 67/400\n",
      "9/9 - 0s - loss: 4.9053e-04 - val_loss: 0.0715\n",
      "Epoch 68/400\n",
      "9/9 - 0s - loss: 5.3657e-04 - val_loss: 0.0765\n",
      "Epoch 69/400\n",
      "9/9 - 0s - loss: 4.3243e-04 - val_loss: 0.0752\n",
      "Epoch 70/400\n",
      "9/9 - 0s - loss: 3.4031e-04 - val_loss: 0.0740\n",
      "Epoch 71/400\n",
      "9/9 - 0s - loss: 2.7311e-04 - val_loss: 0.0729\n",
      "Epoch 72/400\n",
      "9/9 - 0s - loss: 2.7198e-04 - val_loss: 0.0727\n",
      "Epoch 73/400\n",
      "9/9 - 0s - loss: 2.6640e-04 - val_loss: 0.0725\n",
      "Epoch 74/400\n",
      "9/9 - 0s - loss: 3.5450e-04 - val_loss: 0.0724\n",
      "Epoch 75/400\n",
      "9/9 - 0s - loss: 2.8432e-04 - val_loss: 0.0727\n",
      "Epoch 76/400\n",
      "9/9 - 0s - loss: 3.3274e-04 - val_loss: 0.0733\n",
      "Epoch 77/400\n",
      "9/9 - 0s - loss: 2.8770e-04 - val_loss: 0.0706\n",
      "Epoch 78/400\n",
      "9/9 - 0s - loss: 2.1524e-04 - val_loss: 0.0731\n",
      "Epoch 79/400\n",
      "9/9 - 0s - loss: 1.5220e-04 - val_loss: 0.0721\n",
      "Epoch 80/400\n",
      "9/9 - 0s - loss: 1.6874e-04 - val_loss: 0.0714\n",
      "Epoch 81/400\n",
      "9/9 - 0s - loss: 1.7596e-04 - val_loss: 0.0706\n",
      "Epoch 82/400\n",
      "9/9 - 0s - loss: 2.0249e-04 - val_loss: 0.0709\n",
      "Epoch 83/400\n",
      "9/9 - 0s - loss: 2.2326e-04 - val_loss: 0.0695\n",
      "Epoch 84/400\n",
      "9/9 - 0s - loss: 2.1012e-04 - val_loss: 0.0720\n",
      "Epoch 85/400\n",
      "9/9 - 0s - loss: 2.4851e-04 - val_loss: 0.0696\n",
      "Epoch 86/400\n",
      "9/9 - 0s - loss: 2.6840e-04 - val_loss: 0.0727\n",
      "Epoch 87/400\n",
      "9/9 - 0s - loss: 2.1210e-04 - val_loss: 0.0684\n",
      "Epoch 88/400\n",
      "9/9 - 0s - loss: 3.5431e-04 - val_loss: 0.0714\n",
      "Epoch 89/400\n",
      "9/9 - 0s - loss: 5.8279e-04 - val_loss: 0.0716\n",
      "Epoch 90/400\n",
      "9/9 - 0s - loss: 5.1969e-04 - val_loss: 0.0693\n",
      "Epoch 91/400\n",
      "9/9 - 0s - loss: 5.7997e-04 - val_loss: 0.0657\n",
      "Epoch 92/400\n",
      "9/9 - 0s - loss: 0.0016 - val_loss: 0.0743\n",
      "Epoch 93/400\n",
      "9/9 - 0s - loss: 0.0014 - val_loss: 0.0633\n",
      "Epoch 94/400\n",
      "9/9 - 0s - loss: 0.0012 - val_loss: 0.0696\n",
      "Epoch 95/400\n",
      "9/9 - 0s - loss: 0.0011 - val_loss: 0.0702\n",
      "Epoch 96/400\n",
      "9/9 - 0s - loss: 9.9637e-04 - val_loss: 0.0721\n",
      "Epoch 97/400\n",
      "9/9 - 0s - loss: 0.0010 - val_loss: 0.0752\n",
      "Epoch 98/400\n",
      "9/9 - 0s - loss: 0.0011 - val_loss: 0.0641\n",
      "Epoch 99/400\n",
      "9/9 - 0s - loss: 9.1437e-04 - val_loss: 0.0722\n",
      "Epoch 100/400\n",
      "9/9 - 0s - loss: 6.4419e-04 - val_loss: 0.0764\n",
      "Epoch 101/400\n",
      "9/9 - 0s - loss: 5.2850e-04 - val_loss: 0.0705\n",
      "Epoch 102/400\n",
      "9/9 - 0s - loss: 6.4176e-04 - val_loss: 0.0745\n",
      "Epoch 103/400\n",
      "9/9 - 0s - loss: 5.5744e-04 - val_loss: 0.0612\n",
      "Epoch 104/400\n",
      "9/9 - 0s - loss: 6.1548e-04 - val_loss: 0.0694\n",
      "Epoch 105/400\n",
      "9/9 - 0s - loss: 6.1998e-04 - val_loss: 0.0740\n",
      "Epoch 106/400\n",
      "9/9 - 0s - loss: 5.6541e-04 - val_loss: 0.0708\n",
      "Epoch 107/400\n",
      "9/9 - 0s - loss: 7.8253e-04 - val_loss: 0.0712\n",
      "Epoch 108/400\n",
      "9/9 - 0s - loss: 0.0016 - val_loss: 0.0624\n",
      "Epoch 109/400\n",
      "9/9 - 0s - loss: 0.0017 - val_loss: 0.0723\n",
      "Epoch 110/400\n",
      "9/9 - 0s - loss: 0.0015 - val_loss: 0.0721\n",
      "Epoch 111/400\n",
      "9/9 - 0s - loss: 0.0014 - val_loss: 0.0704\n",
      "Epoch 112/400\n",
      "9/9 - 0s - loss: 0.0015 - val_loss: 0.0707\n",
      "Epoch 113/400\n",
      "9/9 - 0s - loss: 0.0020 - val_loss: 0.0715\n",
      "Epoch 114/400\n",
      "9/9 - 0s - loss: 0.0015 - val_loss: 0.0730\n",
      "Epoch 115/400\n",
      "9/9 - 0s - loss: 0.0011 - val_loss: 0.0716\n",
      "Epoch 116/400\n",
      "9/9 - 0s - loss: 8.4491e-04 - val_loss: 0.0663\n",
      "Epoch 117/400\n",
      "9/9 - 0s - loss: 6.0772e-04 - val_loss: 0.0683\n",
      "Epoch 118/400\n",
      "9/9 - 0s - loss: 3.9689e-04 - val_loss: 0.0699\n",
      "Epoch 119/400\n",
      "9/9 - 0s - loss: 4.3220e-04 - val_loss: 0.0668\n",
      "Epoch 120/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 3.5284e-04 - val_loss: 0.0679\n",
      "Epoch 121/400\n",
      "9/9 - 0s - loss: 2.5978e-04 - val_loss: 0.0688\n",
      "Epoch 122/400\n",
      "9/9 - 0s - loss: 2.0388e-04 - val_loss: 0.0689\n",
      "Epoch 123/400\n",
      "9/9 - 0s - loss: 2.7323e-04 - val_loss: 0.0695\n",
      "Epoch 124/400\n",
      "9/9 - 0s - loss: 2.8168e-04 - val_loss: 0.0687\n",
      "Epoch 125/400\n",
      "9/9 - 0s - loss: 2.0999e-04 - val_loss: 0.0667\n",
      "Epoch 126/400\n",
      "9/9 - 0s - loss: 2.1458e-04 - val_loss: 0.0688\n",
      "Epoch 127/400\n",
      "9/9 - 0s - loss: 2.3184e-04 - val_loss: 0.0657\n",
      "Epoch 128/400\n",
      "9/9 - 0s - loss: 2.3296e-04 - val_loss: 0.0694\n",
      "Epoch 129/400\n",
      "9/9 - 0s - loss: 1.3088e-04 - val_loss: 0.0664\n",
      "Epoch 130/400\n",
      "9/9 - 0s - loss: 2.1681e-04 - val_loss: 0.0687\n",
      "Epoch 131/400\n",
      "9/9 - 0s - loss: 1.8245e-04 - val_loss: 0.0684\n",
      "Epoch 132/400\n",
      "9/9 - 0s - loss: 1.5860e-04 - val_loss: 0.0673\n",
      "Epoch 133/400\n",
      "9/9 - 0s - loss: 1.0684e-04 - val_loss: 0.0666\n",
      "Epoch 134/400\n",
      "9/9 - 0s - loss: 1.2158e-04 - val_loss: 0.0683\n",
      "Epoch 135/400\n",
      "9/9 - 0s - loss: 1.1617e-04 - val_loss: 0.0680\n",
      "Epoch 136/400\n",
      "9/9 - 0s - loss: 8.7510e-05 - val_loss: 0.0673\n",
      "Epoch 137/400\n",
      "9/9 - 0s - loss: 7.9621e-05 - val_loss: 0.0655\n",
      "Epoch 138/400\n",
      "9/9 - 0s - loss: 1.0394e-04 - val_loss: 0.0666\n",
      "Epoch 139/400\n",
      "9/9 - 0s - loss: 9.7146e-05 - val_loss: 0.0697\n",
      "Epoch 140/400\n",
      "9/9 - 0s - loss: 1.1438e-04 - val_loss: 0.0659\n",
      "Epoch 141/400\n",
      "9/9 - 0s - loss: 1.1878e-04 - val_loss: 0.0659\n",
      "Epoch 142/400\n",
      "9/9 - 0s - loss: 9.5009e-05 - val_loss: 0.0683\n",
      "Epoch 143/400\n",
      "9/9 - 0s - loss: 8.5769e-05 - val_loss: 0.0680\n",
      "Epoch 144/400\n",
      "9/9 - 0s - loss: 7.5266e-05 - val_loss: 0.0678\n",
      "Epoch 145/400\n",
      "9/9 - 0s - loss: 1.1248e-04 - val_loss: 0.0663\n",
      "Epoch 146/400\n",
      "9/9 - 0s - loss: 8.0487e-05 - val_loss: 0.0667\n",
      "Epoch 147/400\n",
      "9/9 - 0s - loss: 9.3780e-05 - val_loss: 0.0667\n",
      "Epoch 148/400\n",
      "9/9 - 0s - loss: 7.7256e-05 - val_loss: 0.0672\n",
      "Epoch 149/400\n",
      "9/9 - 0s - loss: 6.6666e-05 - val_loss: 0.0642\n",
      "Epoch 150/400\n",
      "9/9 - 0s - loss: 9.2192e-05 - val_loss: 0.0672\n",
      "Epoch 151/400\n",
      "9/9 - 0s - loss: 1.1211e-04 - val_loss: 0.0648\n",
      "Epoch 152/400\n",
      "9/9 - 0s - loss: 1.4365e-04 - val_loss: 0.0677\n",
      "Epoch 153/400\n",
      "9/9 - 0s - loss: 1.4150e-04 - val_loss: 0.0645\n",
      "Epoch 154/400\n",
      "9/9 - 0s - loss: 1.3907e-04 - val_loss: 0.0666\n",
      "Epoch 155/400\n",
      "9/9 - 0s - loss: 1.1206e-04 - val_loss: 0.0666\n",
      "Epoch 156/400\n",
      "9/9 - 0s - loss: 1.6118e-04 - val_loss: 0.0641\n",
      "Epoch 157/400\n",
      "9/9 - 0s - loss: 1.9114e-04 - val_loss: 0.0660\n",
      "Epoch 158/400\n",
      "9/9 - 0s - loss: 1.9412e-04 - val_loss: 0.0647\n",
      "Epoch 159/400\n",
      "9/9 - 0s - loss: 1.9424e-04 - val_loss: 0.0682\n",
      "Epoch 160/400\n",
      "9/9 - 0s - loss: 1.7505e-04 - val_loss: 0.0651\n",
      "Epoch 161/400\n",
      "9/9 - 0s - loss: 1.4427e-04 - val_loss: 0.0628\n",
      "Epoch 162/400\n",
      "9/9 - 0s - loss: 1.2038e-04 - val_loss: 0.0660\n",
      "Epoch 163/400\n",
      "9/9 - 0s - loss: 9.9350e-05 - val_loss: 0.0662\n",
      "Epoch 164/400\n",
      "9/9 - 0s - loss: 9.7814e-05 - val_loss: 0.0638\n",
      "Epoch 165/400\n",
      "9/9 - 0s - loss: 1.0749e-04 - val_loss: 0.0663\n",
      "Epoch 166/400\n",
      "9/9 - 0s - loss: 1.3838e-04 - val_loss: 0.0651\n",
      "Epoch 167/400\n",
      "9/9 - 0s - loss: 2.8295e-04 - val_loss: 0.0701\n",
      "Epoch 168/400\n",
      "9/9 - 0s - loss: 3.1410e-04 - val_loss: 0.0639\n",
      "Epoch 169/400\n",
      "9/9 - 0s - loss: 3.0709e-04 - val_loss: 0.0657\n",
      "Epoch 170/400\n",
      "9/9 - 0s - loss: 3.6931e-04 - val_loss: 0.0645\n",
      "Epoch 171/400\n",
      "9/9 - 0s - loss: 3.9402e-04 - val_loss: 0.0652\n",
      "Epoch 172/400\n",
      "9/9 - 0s - loss: 5.9203e-04 - val_loss: 0.0681\n",
      "Epoch 173/400\n",
      "9/9 - 0s - loss: 7.9294e-04 - val_loss: 0.0654\n",
      "Epoch 174/400\n",
      "9/9 - 0s - loss: 0.0010 - val_loss: 0.0639\n",
      "Epoch 175/400\n",
      "9/9 - 0s - loss: 0.0017 - val_loss: 0.0726\n",
      "Epoch 176/400\n",
      "9/9 - 0s - loss: 0.0018 - val_loss: 0.0663\n",
      "Epoch 177/400\n",
      "9/9 - 0s - loss: 0.0018 - val_loss: 0.0600\n",
      "Epoch 178/400\n",
      "9/9 - 0s - loss: 0.0019 - val_loss: 0.0700\n",
      "Epoch 179/400\n",
      "9/9 - 0s - loss: 0.0043 - val_loss: 0.0696\n",
      "Epoch 180/400\n",
      "9/9 - 0s - loss: 0.0070 - val_loss: 0.0831\n",
      "Epoch 181/400\n",
      "9/9 - 0s - loss: 0.0068 - val_loss: 0.0636\n",
      "Epoch 182/400\n",
      "9/9 - 0s - loss: 0.0077 - val_loss: 0.0904\n",
      "Epoch 183/400\n",
      "9/9 - 0s - loss: 0.0051 - val_loss: 0.0741\n",
      "Epoch 184/400\n",
      "9/9 - 0s - loss: 0.0058 - val_loss: 0.0806\n",
      "Epoch 185/400\n",
      "9/9 - 0s - loss: 0.0050 - val_loss: 0.0888\n",
      "Epoch 186/400\n",
      "9/9 - 0s - loss: 0.0060 - val_loss: 0.0734\n",
      "Epoch 187/400\n",
      "9/9 - 0s - loss: 0.0054 - val_loss: 0.0946\n",
      "Epoch 188/400\n",
      "9/9 - 0s - loss: 0.0045 - val_loss: 0.0779\n",
      "Epoch 189/400\n",
      "9/9 - 0s - loss: 0.0044 - val_loss: 0.1047\n",
      "Epoch 190/400\n",
      "9/9 - 0s - loss: 0.0058 - val_loss: 0.0727\n",
      "Epoch 191/400\n",
      "9/9 - 0s - loss: 0.0065 - val_loss: 0.0707\n",
      "Epoch 192/400\n",
      "9/9 - 0s - loss: 0.0043 - val_loss: 0.0666\n",
      "Epoch 193/400\n",
      "9/9 - 0s - loss: 0.0035 - val_loss: 0.0829\n",
      "Epoch 194/400\n",
      "9/9 - 0s - loss: 0.0019 - val_loss: 0.0725\n",
      "Epoch 195/400\n",
      "9/9 - 0s - loss: 0.0017 - val_loss: 0.0758\n",
      "Epoch 196/400\n",
      "9/9 - 0s - loss: 0.0012 - val_loss: 0.0785\n",
      "Epoch 197/400\n",
      "9/9 - 0s - loss: 0.0010 - val_loss: 0.0727\n",
      "Epoch 198/400\n",
      "9/9 - 0s - loss: 6.3814e-04 - val_loss: 0.0725\n",
      "Epoch 199/400\n",
      "9/9 - 0s - loss: 5.2418e-04 - val_loss: 0.0729\n",
      "Epoch 200/400\n",
      "9/9 - 0s - loss: 4.9202e-04 - val_loss: 0.0730\n",
      "Epoch 201/400\n",
      "9/9 - 0s - loss: 3.7116e-04 - val_loss: 0.0727\n",
      "Epoch 202/400\n",
      "9/9 - 0s - loss: 2.6908e-04 - val_loss: 0.0730\n",
      "Epoch 203/400\n",
      "9/9 - 0s - loss: 2.3089e-04 - val_loss: 0.0737\n",
      "Epoch 204/400\n",
      "9/9 - 0s - loss: 2.7864e-04 - val_loss: 0.0718\n",
      "Epoch 205/400\n",
      "9/9 - 0s - loss: 2.3435e-04 - val_loss: 0.0750\n",
      "Epoch 206/400\n",
      "9/9 - 0s - loss: 2.0579e-04 - val_loss: 0.0673\n",
      "Epoch 207/400\n",
      "9/9 - 0s - loss: 1.6747e-04 - val_loss: 0.0738\n",
      "Epoch 208/400\n",
      "9/9 - 0s - loss: 1.6927e-04 - val_loss: 0.0701\n",
      "Epoch 209/400\n",
      "9/9 - 0s - loss: 2.1732e-04 - val_loss: 0.0724\n",
      "Epoch 210/400\n",
      "9/9 - 0s - loss: 1.5677e-04 - val_loss: 0.0744\n",
      "Epoch 211/400\n",
      "9/9 - 0s - loss: 1.8187e-04 - val_loss: 0.0704\n",
      "Epoch 212/400\n",
      "9/9 - 0s - loss: 2.2170e-04 - val_loss: 0.0708\n",
      "Epoch 213/400\n",
      "9/9 - 0s - loss: 1.4990e-04 - val_loss: 0.0740\n",
      "Epoch 214/400\n",
      "9/9 - 0s - loss: 1.5732e-04 - val_loss: 0.0705\n",
      "Epoch 215/400\n",
      "9/9 - 0s - loss: 1.0289e-04 - val_loss: 0.0728\n",
      "Epoch 216/400\n",
      "9/9 - 0s - loss: 1.0396e-04 - val_loss: 0.0716\n",
      "Epoch 217/400\n",
      "9/9 - 0s - loss: 1.2690e-04 - val_loss: 0.0713\n",
      "Epoch 218/400\n",
      "9/9 - 0s - loss: 1.3584e-04 - val_loss: 0.0701\n",
      "Epoch 219/400\n",
      "9/9 - 0s - loss: 1.2251e-04 - val_loss: 0.0693\n",
      "Epoch 220/400\n",
      "9/9 - 0s - loss: 9.1518e-05 - val_loss: 0.0704\n",
      "Epoch 221/400\n",
      "9/9 - 0s - loss: 1.0206e-04 - val_loss: 0.0698\n",
      "Epoch 222/400\n",
      "9/9 - 0s - loss: 7.9723e-05 - val_loss: 0.0697\n",
      "Epoch 223/400\n",
      "9/9 - 0s - loss: 6.8964e-05 - val_loss: 0.0708\n",
      "Epoch 224/400\n",
      "9/9 - 0s - loss: 5.7575e-05 - val_loss: 0.0686\n",
      "Epoch 225/400\n",
      "9/9 - 0s - loss: 5.0078e-05 - val_loss: 0.0716\n",
      "Epoch 226/400\n",
      "9/9 - 0s - loss: 5.5434e-05 - val_loss: 0.0699\n",
      "Epoch 227/400\n",
      "9/9 - 0s - loss: 4.2726e-05 - val_loss: 0.0700\n",
      "Epoch 228/400\n",
      "9/9 - 0s - loss: 4.0204e-05 - val_loss: 0.0692\n",
      "Epoch 229/400\n",
      "9/9 - 0s - loss: 4.4796e-05 - val_loss: 0.0704\n",
      "Epoch 230/400\n",
      "9/9 - 0s - loss: 4.0658e-05 - val_loss: 0.0705\n",
      "Epoch 231/400\n",
      "9/9 - 0s - loss: 6.2872e-05 - val_loss: 0.0679\n",
      "Epoch 232/400\n",
      "9/9 - 0s - loss: 6.1336e-05 - val_loss: 0.0706\n",
      "Epoch 233/400\n",
      "9/9 - 0s - loss: 6.4620e-05 - val_loss: 0.0682\n",
      "Epoch 234/400\n",
      "9/9 - 0s - loss: 6.3646e-05 - val_loss: 0.0702\n",
      "Epoch 235/400\n",
      "9/9 - 0s - loss: 5.9845e-05 - val_loss: 0.0671\n",
      "Epoch 236/400\n",
      "9/9 - 0s - loss: 5.0467e-05 - val_loss: 0.0705\n",
      "Epoch 237/400\n",
      "9/9 - 0s - loss: 6.6779e-05 - val_loss: 0.0675\n",
      "Epoch 238/400\n",
      "9/9 - 0s - loss: 7.6920e-05 - val_loss: 0.0693\n",
      "Epoch 239/400\n",
      "9/9 - 0s - loss: 5.4847e-05 - val_loss: 0.0669\n",
      "Epoch 240/400\n",
      "9/9 - 0s - loss: 6.6289e-05 - val_loss: 0.0705\n",
      "Epoch 241/400\n",
      "9/9 - 0s - loss: 7.3355e-05 - val_loss: 0.0668\n",
      "Epoch 242/400\n",
      "9/9 - 0s - loss: 7.6174e-05 - val_loss: 0.0718\n",
      "Epoch 243/400\n",
      "9/9 - 0s - loss: 7.5128e-05 - val_loss: 0.0669\n",
      "Epoch 244/400\n",
      "9/9 - 0s - loss: 6.7118e-05 - val_loss: 0.0704\n",
      "Epoch 245/400\n",
      "9/9 - 0s - loss: 6.5701e-05 - val_loss: 0.0681\n",
      "Epoch 246/400\n",
      "9/9 - 0s - loss: 6.6409e-05 - val_loss: 0.0705\n",
      "Epoch 247/400\n",
      "9/9 - 0s - loss: 7.0537e-05 - val_loss: 0.0673\n",
      "Epoch 248/400\n",
      "9/9 - 0s - loss: 9.1814e-05 - val_loss: 0.0680\n",
      "Epoch 249/400\n",
      "9/9 - 0s - loss: 9.8481e-05 - val_loss: 0.0683\n",
      "Epoch 250/400\n",
      "9/9 - 0s - loss: 8.5988e-05 - val_loss: 0.0688\n",
      "Epoch 251/400\n",
      "9/9 - 0s - loss: 8.4124e-05 - val_loss: 0.0678\n",
      "Epoch 252/400\n",
      "9/9 - 0s - loss: 7.6278e-05 - val_loss: 0.0690\n",
      "Epoch 253/400\n",
      "9/9 - 0s - loss: 9.0553e-05 - val_loss: 0.0675\n",
      "Epoch 254/400\n",
      "9/9 - 0s - loss: 8.6224e-05 - val_loss: 0.0698\n",
      "Epoch 255/400\n",
      "9/9 - 0s - loss: 1.0635e-04 - val_loss: 0.0662\n",
      "Epoch 256/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 1.3412e-04 - val_loss: 0.0708\n",
      "Epoch 257/400\n",
      "9/9 - 0s - loss: 1.6243e-04 - val_loss: 0.0660\n",
      "Epoch 258/400\n",
      "9/9 - 0s - loss: 1.6161e-04 - val_loss: 0.0733\n",
      "Epoch 259/400\n",
      "9/9 - 0s - loss: 2.1960e-04 - val_loss: 0.0648\n",
      "Epoch 260/400\n",
      "9/9 - 0s - loss: 2.4243e-04 - val_loss: 0.0722\n",
      "Epoch 261/400\n",
      "9/9 - 0s - loss: 2.5541e-04 - val_loss: 0.0700\n",
      "Epoch 262/400\n",
      "9/9 - 0s - loss: 1.7298e-04 - val_loss: 0.0680\n",
      "Epoch 263/400\n",
      "9/9 - 0s - loss: 2.2468e-04 - val_loss: 0.0664\n",
      "Epoch 264/400\n",
      "9/9 - 0s - loss: 2.6212e-04 - val_loss: 0.0703\n",
      "Epoch 265/400\n",
      "9/9 - 0s - loss: 3.2452e-04 - val_loss: 0.0654\n",
      "Epoch 266/400\n",
      "9/9 - 0s - loss: 3.4440e-04 - val_loss: 0.0678\n",
      "Epoch 267/400\n",
      "9/9 - 0s - loss: 2.6370e-04 - val_loss: 0.0692\n",
      "Epoch 268/400\n",
      "9/9 - 0s - loss: 2.0205e-04 - val_loss: 0.0684\n",
      "Epoch 269/400\n",
      "9/9 - 0s - loss: 1.6671e-04 - val_loss: 0.0678\n",
      "Epoch 270/400\n",
      "9/9 - 0s - loss: 1.4204e-04 - val_loss: 0.0671\n",
      "Epoch 271/400\n",
      "9/9 - 0s - loss: 1.5911e-04 - val_loss: 0.0701\n",
      "Epoch 272/400\n",
      "9/9 - 0s - loss: 1.4976e-04 - val_loss: 0.0678\n",
      "Epoch 273/400\n",
      "9/9 - 0s - loss: 1.9451e-04 - val_loss: 0.0665\n",
      "Epoch 274/400\n",
      "9/9 - 0s - loss: 1.5975e-04 - val_loss: 0.0693\n",
      "Epoch 275/400\n",
      "9/9 - 0s - loss: 1.3993e-04 - val_loss: 0.0660\n",
      "Epoch 276/400\n",
      "9/9 - 0s - loss: 1.3817e-04 - val_loss: 0.0705\n",
      "Epoch 277/400\n",
      "9/9 - 0s - loss: 1.3721e-04 - val_loss: 0.0641\n",
      "Epoch 278/400\n",
      "9/9 - 0s - loss: 1.6443e-04 - val_loss: 0.0716\n",
      "Epoch 279/400\n",
      "9/9 - 0s - loss: 1.2713e-04 - val_loss: 0.0646\n",
      "Epoch 280/400\n",
      "9/9 - 0s - loss: 1.9329e-04 - val_loss: 0.0780\n",
      "Epoch 281/400\n",
      "9/9 - 0s - loss: 3.0236e-04 - val_loss: 0.0673\n",
      "Epoch 282/400\n",
      "9/9 - 0s - loss: 2.6483e-04 - val_loss: 0.0679\n",
      "Epoch 283/400\n",
      "9/9 - 0s - loss: 1.8923e-04 - val_loss: 0.0685\n",
      "Epoch 284/400\n",
      "9/9 - 0s - loss: 2.8597e-04 - val_loss: 0.0673\n",
      "Epoch 285/400\n",
      "9/9 - 0s - loss: 4.2828e-04 - val_loss: 0.0635\n",
      "Epoch 286/400\n",
      "9/9 - 0s - loss: 3.4856e-04 - val_loss: 0.0717\n",
      "Epoch 287/400\n",
      "9/9 - 1s - loss: 2.8573e-04 - val_loss: 0.0676\n",
      "Epoch 288/400\n",
      "9/9 - 0s - loss: 2.5829e-04 - val_loss: 0.0673\n",
      "Epoch 289/400\n",
      "9/9 - 0s - loss: 1.7179e-04 - val_loss: 0.0673\n",
      "Epoch 290/400\n",
      "9/9 - 0s - loss: 1.7026e-04 - val_loss: 0.0700\n",
      "Epoch 291/400\n",
      "9/9 - 0s - loss: 1.7575e-04 - val_loss: 0.0681\n",
      "Epoch 292/400\n",
      "9/9 - 0s - loss: 1.8432e-04 - val_loss: 0.0677\n",
      "Epoch 293/400\n",
      "9/9 - 0s - loss: 2.2762e-04 - val_loss: 0.0686\n",
      "Epoch 294/400\n",
      "9/9 - 0s - loss: 1.9351e-04 - val_loss: 0.0668\n",
      "Epoch 295/400\n",
      "9/9 - 0s - loss: 2.1398e-04 - val_loss: 0.0684\n",
      "Epoch 296/400\n",
      "9/9 - 0s - loss: 2.3171e-04 - val_loss: 0.0678\n",
      "Epoch 297/400\n",
      "9/9 - 0s - loss: 3.1691e-04 - val_loss: 0.0668\n",
      "Epoch 298/400\n",
      "9/9 - 0s - loss: 5.3403e-04 - val_loss: 0.0686\n",
      "Epoch 299/400\n",
      "9/9 - 0s - loss: 0.0011 - val_loss: 0.0737\n",
      "Epoch 300/400\n",
      "9/9 - 0s - loss: 9.8307e-04 - val_loss: 0.0664\n",
      "Epoch 301/400\n",
      "9/9 - 0s - loss: 0.0015 - val_loss: 0.0649\n",
      "Epoch 302/400\n",
      "9/9 - 0s - loss: 0.0019 - val_loss: 0.0649\n",
      "Epoch 303/400\n",
      "9/9 - 0s - loss: 0.0016 - val_loss: 0.0709\n",
      "Epoch 304/400\n",
      "9/9 - 0s - loss: 0.0021 - val_loss: 0.0577\n",
      "Epoch 305/400\n",
      "9/9 - 0s - loss: 0.0025 - val_loss: 0.0722\n",
      "Epoch 306/400\n",
      "9/9 - 0s - loss: 0.0019 - val_loss: 0.0622\n",
      "Epoch 307/400\n",
      "9/9 - 0s - loss: 0.0017 - val_loss: 0.0624\n",
      "Epoch 308/400\n",
      "9/9 - 0s - loss: 0.0013 - val_loss: 0.0619\n",
      "Epoch 309/400\n",
      "9/9 - 0s - loss: 0.0010 - val_loss: 0.0647\n",
      "Epoch 310/400\n",
      "9/9 - 0s - loss: 8.1020e-04 - val_loss: 0.0681\n",
      "Epoch 311/400\n",
      "9/9 - 0s - loss: 7.8307e-04 - val_loss: 0.0741\n",
      "Epoch 312/400\n",
      "9/9 - 0s - loss: 0.0011 - val_loss: 0.0587\n",
      "Epoch 313/400\n",
      "9/9 - 0s - loss: 6.8944e-04 - val_loss: 0.0712\n",
      "Epoch 314/400\n",
      "9/9 - 0s - loss: 5.4989e-04 - val_loss: 0.0686\n",
      "Epoch 315/400\n",
      "9/9 - 0s - loss: 5.2270e-04 - val_loss: 0.0630\n",
      "Epoch 316/400\n",
      "9/9 - 0s - loss: 6.9868e-04 - val_loss: 0.0700\n",
      "Epoch 317/400\n",
      "9/9 - 0s - loss: 7.7003e-04 - val_loss: 0.0720\n",
      "Epoch 318/400\n",
      "9/9 - 0s - loss: 4.9154e-04 - val_loss: 0.0644\n",
      "Epoch 319/400\n",
      "9/9 - 0s - loss: 3.4798e-04 - val_loss: 0.0713\n",
      "Epoch 320/400\n",
      "9/9 - 0s - loss: 2.7382e-04 - val_loss: 0.0641\n",
      "Epoch 321/400\n",
      "9/9 - 0s - loss: 2.3246e-04 - val_loss: 0.0690\n",
      "Epoch 322/400\n",
      "9/9 - 0s - loss: 2.4730e-04 - val_loss: 0.0657\n",
      "Epoch 323/400\n",
      "9/9 - 0s - loss: 2.6217e-04 - val_loss: 0.0710\n",
      "Epoch 324/400\n",
      "9/9 - 0s - loss: 3.4734e-04 - val_loss: 0.0653\n",
      "Epoch 325/400\n",
      "9/9 - 0s - loss: 3.5728e-04 - val_loss: 0.0702\n",
      "Epoch 326/400\n",
      "9/9 - 0s - loss: 2.9393e-04 - val_loss: 0.0644\n",
      "Epoch 327/400\n",
      "9/9 - 0s - loss: 3.7181e-04 - val_loss: 0.0745\n",
      "Epoch 328/400\n",
      "9/9 - 0s - loss: 3.7164e-04 - val_loss: 0.0673\n",
      "Epoch 329/400\n",
      "9/9 - 0s - loss: 3.7529e-04 - val_loss: 0.0665\n",
      "Epoch 330/400\n",
      "9/9 - 0s - loss: 4.0611e-04 - val_loss: 0.0675\n",
      "Epoch 331/400\n",
      "9/9 - 0s - loss: 3.1439e-04 - val_loss: 0.0658\n",
      "Epoch 332/400\n",
      "9/9 - 0s - loss: 2.4393e-04 - val_loss: 0.0689\n",
      "Epoch 333/400\n",
      "9/9 - 0s - loss: 2.0685e-04 - val_loss: 0.0635\n",
      "Epoch 334/400\n",
      "9/9 - 0s - loss: 1.3705e-04 - val_loss: 0.0663\n",
      "Epoch 335/400\n",
      "9/9 - 0s - loss: 9.1465e-05 - val_loss: 0.0671\n",
      "Epoch 336/400\n",
      "9/9 - 0s - loss: 8.2501e-05 - val_loss: 0.0655\n",
      "Epoch 337/400\n",
      "9/9 - 0s - loss: 1.0373e-04 - val_loss: 0.0682\n",
      "Epoch 338/400\n",
      "9/9 - 0s - loss: 9.1922e-05 - val_loss: 0.0664\n",
      "Epoch 339/400\n",
      "9/9 - 0s - loss: 7.3904e-05 - val_loss: 0.0676\n",
      "Epoch 340/400\n",
      "9/9 - 0s - loss: 6.7605e-05 - val_loss: 0.0657\n",
      "Epoch 341/400\n",
      "9/9 - 0s - loss: 6.1558e-05 - val_loss: 0.0666\n",
      "Epoch 342/400\n",
      "9/9 - 0s - loss: 6.9340e-05 - val_loss: 0.0677\n",
      "Epoch 343/400\n",
      "9/9 - 0s - loss: 5.6171e-05 - val_loss: 0.0651\n",
      "Epoch 344/400\n",
      "9/9 - 0s - loss: 6.8490e-05 - val_loss: 0.0670\n",
      "Epoch 345/400\n",
      "9/9 - 0s - loss: 6.0128e-05 - val_loss: 0.0677\n",
      "Epoch 346/400\n",
      "9/9 - 0s - loss: 6.0392e-05 - val_loss: 0.0658\n",
      "Epoch 347/400\n",
      "9/9 - 0s - loss: 7.4665e-05 - val_loss: 0.0675\n",
      "Epoch 348/400\n",
      "9/9 - 0s - loss: 7.5354e-05 - val_loss: 0.0663\n",
      "Epoch 349/400\n",
      "9/9 - 0s - loss: 1.0223e-04 - val_loss: 0.0678\n",
      "Epoch 350/400\n",
      "9/9 - 0s - loss: 9.6329e-05 - val_loss: 0.0665\n",
      "Epoch 351/400\n",
      "9/9 - 0s - loss: 9.4525e-05 - val_loss: 0.0684\n",
      "Epoch 352/400\n",
      "9/9 - 0s - loss: 9.1601e-05 - val_loss: 0.0644\n",
      "Epoch 353/400\n",
      "9/9 - 0s - loss: 6.2556e-05 - val_loss: 0.0684\n",
      "Epoch 354/400\n",
      "9/9 - 0s - loss: 5.6311e-05 - val_loss: 0.0667\n",
      "Epoch 355/400\n",
      "9/9 - 0s - loss: 6.2754e-05 - val_loss: 0.0670\n",
      "Epoch 356/400\n",
      "9/9 - 0s - loss: 5.3068e-05 - val_loss: 0.0677\n",
      "Epoch 357/400\n",
      "9/9 - 0s - loss: 4.5144e-05 - val_loss: 0.0663\n",
      "Epoch 358/400\n",
      "9/9 - 0s - loss: 5.2950e-05 - val_loss: 0.0680\n",
      "Epoch 359/400\n",
      "9/9 - 0s - loss: 4.2716e-05 - val_loss: 0.0667\n",
      "Epoch 360/400\n",
      "9/9 - 0s - loss: 4.6982e-05 - val_loss: 0.0695\n",
      "Epoch 361/400\n",
      "9/9 - 0s - loss: 6.7308e-05 - val_loss: 0.0659\n",
      "Epoch 362/400\n",
      "9/9 - 0s - loss: 6.6840e-05 - val_loss: 0.0684\n",
      "Epoch 363/400\n",
      "9/9 - 0s - loss: 5.8664e-05 - val_loss: 0.0680\n",
      "Epoch 364/400\n",
      "9/9 - 0s - loss: 4.5369e-05 - val_loss: 0.0678\n",
      "Epoch 365/400\n",
      "9/9 - 1s - loss: 4.2235e-05 - val_loss: 0.0659\n",
      "Epoch 366/400\n",
      "9/9 - 0s - loss: 4.6670e-05 - val_loss: 0.0675\n",
      "Epoch 367/400\n",
      "9/9 - 0s - loss: 3.7900e-05 - val_loss: 0.0668\n",
      "Epoch 368/400\n",
      "9/9 - 0s - loss: 2.7663e-05 - val_loss: 0.0669\n",
      "Epoch 369/400\n",
      "9/9 - 1s - loss: 2.6920e-05 - val_loss: 0.0672\n",
      "Epoch 370/400\n",
      "9/9 - 1s - loss: 2.5701e-05 - val_loss: 0.0678\n",
      "Epoch 371/400\n",
      "9/9 - 0s - loss: 2.9469e-05 - val_loss: 0.0669\n",
      "Epoch 372/400\n",
      "9/9 - 0s - loss: 3.7201e-05 - val_loss: 0.0672\n",
      "Epoch 373/400\n",
      "9/9 - 0s - loss: 5.4889e-05 - val_loss: 0.0681\n",
      "Epoch 374/400\n",
      "9/9 - 0s - loss: 4.8643e-05 - val_loss: 0.0684\n",
      "Epoch 375/400\n",
      "9/9 - 0s - loss: 5.9707e-05 - val_loss: 0.0678\n",
      "Epoch 376/400\n",
      "9/9 - 0s - loss: 5.7779e-05 - val_loss: 0.0676\n",
      "Epoch 377/400\n",
      "9/9 - 0s - loss: 6.6171e-05 - val_loss: 0.0678\n",
      "Epoch 378/400\n",
      "9/9 - 0s - loss: 5.8583e-05 - val_loss: 0.0681\n",
      "Epoch 379/400\n",
      "9/9 - 0s - loss: 5.3726e-05 - val_loss: 0.0678\n",
      "Epoch 380/400\n",
      "9/9 - 0s - loss: 3.4598e-05 - val_loss: 0.0665\n",
      "Epoch 381/400\n",
      "9/9 - 0s - loss: 4.1587e-05 - val_loss: 0.0675\n",
      "Epoch 382/400\n",
      "9/9 - 0s - loss: 4.5862e-05 - val_loss: 0.0666\n",
      "Epoch 383/400\n",
      "9/9 - 0s - loss: 4.4412e-05 - val_loss: 0.0663\n",
      "Epoch 384/400\n",
      "9/9 - 0s - loss: 5.5476e-05 - val_loss: 0.0665\n",
      "Epoch 385/400\n",
      "9/9 - 0s - loss: 9.2865e-05 - val_loss: 0.0663\n",
      "Epoch 386/400\n",
      "9/9 - 0s - loss: 1.0807e-04 - val_loss: 0.0692\n",
      "Epoch 387/400\n",
      "9/9 - 0s - loss: 1.3439e-04 - val_loss: 0.0669\n",
      "Epoch 388/400\n",
      "9/9 - 0s - loss: 1.3512e-04 - val_loss: 0.0678\n",
      "Epoch 389/400\n",
      "9/9 - 0s - loss: 1.5249e-04 - val_loss: 0.0653\n",
      "Epoch 390/400\n",
      "9/9 - 1s - loss: 1.8184e-04 - val_loss: 0.0691\n",
      "Epoch 391/400\n",
      "9/9 - 0s - loss: 1.5126e-04 - val_loss: 0.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/400\n",
      "9/9 - 0s - loss: 1.8602e-04 - val_loss: 0.0677\n",
      "Epoch 393/400\n",
      "9/9 - 0s - loss: 2.6355e-04 - val_loss: 0.0680\n",
      "Epoch 394/400\n",
      "9/9 - 0s - loss: 5.1859e-04 - val_loss: 0.0674\n",
      "Epoch 395/400\n",
      "9/9 - 0s - loss: 5.7980e-04 - val_loss: 0.0679\n",
      "Epoch 396/400\n",
      "9/9 - 0s - loss: 9.2773e-04 - val_loss: 0.0714\n",
      "Epoch 397/400\n",
      "9/9 - 0s - loss: 9.3188e-04 - val_loss: 0.0703\n",
      "Epoch 398/400\n",
      "9/9 - 1s - loss: 0.0014 - val_loss: 0.0596\n",
      "Epoch 399/400\n",
      "9/9 - 0s - loss: 0.0026 - val_loss: 0.0563\n",
      "Epoch 400/400\n",
      "9/9 - 0s - loss: 0.0027 - val_loss: 0.0767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14bb76a6f2b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train_ensemble1, s_train_ensemble2, X_train_ensemble1, X_train_ensemble2, y_train_ensemble1, y_train_ensemble2= train_test_split(s_train_ensemble, X_train_ensemble, y_train_ensemble, test_size=0.2)\n",
    "print(s_train_ensemble1.shape)\n",
    "base_model = Model(inputs = input_dim, outputs = final_layer)\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "# Compile the Model\n",
    "base_model.compile(optimizer = optimizer, loss = 'mse')\n",
    "base_model.summary()\n",
    "base_model.fit(X_train_ensemble1, y_train_ensemble1,validation_split = 0.1, epochs = 400,\n",
    "                batch_size = 64,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9be6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = Model(inputs = input_dim, outputs = layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084e9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred,y_true):\n",
    "    mse = np.mean((y_pred-y_true)**2)\n",
    "    return mse\n",
    "\n",
    "def mae(y_pred,y_true):\n",
    "    mae = np.mean(np.absolute(y_pred-y_true))\n",
    "    return mae\n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train,X_test,y_test):\n",
    "    # DeepKriging model for continuous data\n",
    "    ensemble_model = Sequential()\n",
    "\n",
    "    ensemble_model.add(base_model1)\n",
    "#     ensemble_model.add(Dense(50, activation = \"relu\"))\n",
    "    ensemble_model.add(Dense(50, activation = \"relu\"))\n",
    "    ensemble_model.add(Dense(2, activation='linear'))\n",
    "    ensemble_model.layers[-3].trainable = False\n",
    "    optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "    ensemble_model.compile(optimizer=optimizer, loss='mse', metrics=['mse','mae'])\n",
    "    ensemble_model.fit(X_train, y_train,\n",
    "                       validation_data=(X_test,y_test), epochs = 200, batch_size = 64, verbose = 0)\n",
    "    return ensemble_model\n",
    "\n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, Y_train):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        x_train, x_test,y_train,y_test = train_test_split(X_train,Y_train,test_size = 0.2)\n",
    "        # define and fit the model on the training set\n",
    "        model = fit_model(x_train, y_train,x_test,y_test)\n",
    "        # evaluate model on the test set\n",
    "        yhat = model.predict(x_test, verbose=0)\n",
    "        mae1 = mae(yhat, y_test)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae1))\n",
    "        # store the model\n",
    "        ensemble.append(model)\n",
    "    return ensemble\n",
    "def y_list_uni(yhat,i):\n",
    "    the_list = list()\n",
    "    for j in range(len(yhat)):\n",
    "        the_list.append(yhat[j][0][i])\n",
    "    return the_list\n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def variance(data):\n",
    "    # Number of observations\n",
    "    n = len(data)\n",
    "    # Mean of the data\n",
    "    mean = sum(data) / n\n",
    "    # Square deviations\n",
    "    deviations = [(x - mean) ** 2 for x in data]\n",
    "    # Variance\n",
    "    variance = sum(deviations) / (n-1)\n",
    "    return variance\n",
    "def predict_with_pi(ensemble, X):\n",
    "    # make predictions\n",
    "    quantiles1 = []\n",
    "    quantiles2 = []\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat=np.asarray(yhat)\n",
    "    \n",
    "    var1_pred = np.asarray(y_list_uni(yhat,0))\n",
    "    var2_pred = np.asarray(y_list_uni(yhat,1))\n",
    "    probabilities = [0.025,0.975]\n",
    "    for i in range(len(probabilities)):\n",
    "        quantiles1.append(np.quantile(var1_pred,probabilities[i]))\n",
    "        quantiles2.append(np.quantile(var2_pred,probabilities[i]))\n",
    "#     y_list_uni = \n",
    "    # calculate 95% gaussian prediction interval\n",
    "    mean1 = var1_pred.mean()\n",
    "    var1 = variance(var1_pred)\n",
    "    mean2 = var2_pred.mean()\n",
    "    var2 = variance(var2_pred)\n",
    "    return mean1, var1, mean2, var2, quantiles1,quantiles2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3b5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit ensemble\n",
    "start_time = time.time()\n",
    "n_members = 10\n",
    "ensemble = fit_ensemble(n_members, X_train_ensemble, y_train_ensemble)\n",
    "\n",
    "# train data mean and variance vectors\n",
    "\n",
    "mean_vec1 = list()\n",
    "mean_vec2 = list()\n",
    "var_vec1 = list()\n",
    "var_vec2 = list()\n",
    "\n",
    "for i in range(X_train_mse.shape[0]):\n",
    "    newX = np.asarray([X_train_mse[i, :]])\n",
    "    mean1,var1,mean2,var2,_ ,__= predict_with_pi(ensemble, newX)\n",
    "    mean_vec1.append(mean1)\n",
    "    mean_vec2.append(mean2)\n",
    "    var_vec1.append(var1)\n",
    "    var_vec2.append(var2)\n",
    "    print(i)\n",
    "end_time = time.time()\n",
    "print(\"%s seconds\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406b1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random error calculation on training data\n",
    "r1 = list()\n",
    "r2 = list()\n",
    "r1 = (y_train_mse[:,0] - mean_vec1)**2 - var_vec1\n",
    "for i in range(len(r1)):\n",
    "    if r1[i] < 0: r1[i] = 0.0\n",
    "r2 = (y_train_mse[:,1] - mean_vec2)**2 - var_vec2\n",
    "for i in range(len(r2)):\n",
    "    if r2[i] < 0: r2[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c24457f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(s1,s2):\n",
    "    return(np.sqrt((s1[0] - s2[0])**2 + (s1[1] - s2[1])**2))\n",
    "\n",
    "def get_nearest_data(s_train,s_test,r,k):\n",
    "    dist_mat = np.zeros((len(s_test),len(s_train)))\n",
    "    nearest_var = np.zeros((len(s_test)))\n",
    "    for i in range(len(s_train)):\n",
    "        for j in range(len(s_test)):\n",
    "            dist_mat[j][i] = calc_distance(s_train[i],s_test[j])\n",
    "    for i in range(len(s_test)):\n",
    "        a = dist_mat[i]\n",
    "        b = np.argpartition(a,k)[:k]\n",
    "        y_val = []\n",
    "        for index in b:\n",
    "            y_val.append(r[index])\n",
    "        nearest_var[i] = (np.mean(y_val))\n",
    "    return nearest_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3662fb4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-55e3277d752b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../test_data_nonstationary.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0ms_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"var1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"var2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "### Test data \n",
    "\n",
    "df_test = pd.read_csv(\"../test_data_nonstationary.csv\", sep = \",\")\n",
    "s_test = np.vstack((df_test[\"x\"],df_test[\"y\"])).T\n",
    "y_test = np.array(df_test[[\"var1\",\"var2\"]])\n",
    "\n",
    "# mean and variance vector for prediction data\n",
    "N = len(df_test)\n",
    "s = s_test\n",
    "num_basis = [2**2,5**2,9**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "#knots_1d = [np.linspace(0,1,i) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + K] = 0\n",
    "    K = K + num_basis[res]\n",
    "encoder_test = phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3525673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random error calculation on test data with neighbourhood approach\n",
    "r1_pred = get_nearest_data(s_train_mse,s_test,r1,10)\n",
    "r2_pred = get_nearest_data(s_train_mse,s_test,r2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45b4f15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "# test data bounds \n",
    "mean_vec1 = list()\n",
    "mean_vec2 = list()\n",
    "var_vec1 = list()\n",
    "var_vec2 = list()\n",
    "l_quantile1 = list()\n",
    "u_quantile1 = list()\n",
    "l_quantile2 = list()\n",
    "u_quantile2 = list()\n",
    "for i in range(encoder_test.shape[0]):\n",
    "    newX = np.asarray([encoder_test[i, :]])\n",
    "    mean1,var1,mean2,var2,quantile1,quantile2 = predict_with_pi(ensemble, newX)\n",
    "    mean_vec1.append(mean1)\n",
    "    mean_vec2.append(mean2)\n",
    "    var_vec1.append(var1)\n",
    "    var_vec2.append(var2)\n",
    "    l_quantile1.append(quantile1[0])\n",
    "    u_quantile1.append(quantile1[1])\n",
    "    l_quantile2.append(quantile2[0])\n",
    "    u_quantile2.append(quantile2[1])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d09b8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = list()\n",
    "# for i in range(len(r1_pred)):\n",
    "#     e.append(r1_pred[i][0])\n",
    "# print(len(var_vec1))\n",
    "# error_vec2 = model_mse2.predict(encoder_test)\n",
    "var_vec1 = np.asarray(var_vec1)\n",
    "var_vec2 = np.asarray(var_vec2)\n",
    "# e = np.asarray(e)\n",
    "lower_bound1 = mean_vec1 - 1.96*np.sqrt(var_vec1 + r1_pred)\n",
    "upper_bound1 = mean_vec1 + 1.96*np.sqrt(var_vec1 + r1_pred)\n",
    "lower_bound2 = mean_vec2 - 1.96*np.sqrt(var_vec2 + r2_pred)\n",
    "upper_bound2 = mean_vec2 + 1.96*np.sqrt(var_vec2 + r2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28db2060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05416666666666667,0.04583333333333333\n",
      "0.13623351655125943,0.1863167077162933\n"
     ]
    }
   ],
   "source": [
    "# Training case\n",
    "count_var0 = 0\n",
    "count_var1 = 0\n",
    "for i in range(len(y_test)):\n",
    "    if ((y_test[i,0] < lower_bound1[i]) or (y_test[i,0] > upper_bound1[i])): count_var0 +=1\n",
    "    if y_test[i,1] < lower_bound2[i] or y_test[i,1] > upper_bound2[i]: count_var1 +=1\n",
    "picp1 = count_var0/len(y_test)\n",
    "picp2 = count_var1/len(y_test)\n",
    "print(str(picp1)+\",\"+str(picp2))\n",
    "width1 = np.mean(upper_bound1 - lower_bound1)\n",
    "width2 = np.mean(upper_bound2 - lower_bound2)\n",
    "print(str(width1)+\",\"+str(width2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b35213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0125,0.02\n",
      "0.12593444431744494,0.17568411271396628\n"
     ]
    }
   ],
   "source": [
    "# Test data case\n",
    "count_var0 = 0\n",
    "count_var1 = 0\n",
    "for i in range(len(y_test)):\n",
    "    if ((y_test[i,0] < lower_bound1[i]) or (y_test[i,0] > upper_bound1[i])): count_var0 +=1\n",
    "    if y_test[i,1] < lower_bound2[i] or y_test[i,1] > upper_bound2[i]: count_var1 +=1\n",
    "picp1 = count_var0/len(y_test)\n",
    "picp2 = count_var1/len(y_test)\n",
    "print(str(picp1)+\",\"+str(picp2))\n",
    "width1 = np.mean(upper_bound1 - lower_bound1)\n",
    "width2 = np.mean(upper_bound2 - lower_bound2)\n",
    "print(str(width1)+\",\"+str(width2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9debd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bounds = pd.DataFrame(np.vstack((lower_bound1,upper_bound1,lower_bound2,upper_bound2)).T,\n",
    "                         columns = [\"l1\",\"u1\",\"l2\",\"u2\"])\n",
    "df_bounds.to_csv(\"../plot_results/bounds_nonstationary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548318f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
