{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1b05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization,Input, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as Kb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "# Library for Gaussian process\n",
    "# import GPy\n",
    "##Library for visualization\n",
    "import matplotlib.pyplot as plt4\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib;matplotlib.rcParams['figure.figsize'] = (15,15)\n",
    "import pylab \n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d737689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = pd.read_csv(\"../synthetic_data_simulations/2d_gaussian_1200_1.csv\", sep = \",\")\n",
    "# df_loc = pd.read_csv(\"../2D_biv_matern_large.csv\", sep = \",\")\n",
    "\n",
    "N = len(df_loc)\n",
    "s = np.vstack((df_loc[\"x\"],df_loc[\"y\"])).T\n",
    "y = np.array(df_loc[[\"var1\",\"var2\"]])\n",
    "\n",
    "### Basis functions\n",
    "\n",
    "num_basis = [5**2,7**2,9**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "#knots_1d = [np.linspace(0,1,i) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + K] = 0\n",
    "    K = K + num_basis[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd691a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 155)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d06b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7e713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model layers \n",
    "\n",
    "input_dim = Input(shape = (phi.shape[1], ))\n",
    "layer1 = Dense(100, kernel_initializer='he_uniform', activation = 'relu')(input_dim)\n",
    "layer2 = Dense(100, activation = 'relu')(layer1)\n",
    "layer3 = Dense(100, activation = 'relu')(layer2)\n",
    "layer4 = Dense(100, activation = 'relu')(layer3)\n",
    "layer5 = Dense(50, activation = 'relu')(layer4)\n",
    "layer6 = Dense(50, activation = 'relu')(layer5)\n",
    "final_layer = Dense(2, activation = 'linear')(layer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de0ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 2)\n"
     ]
    }
   ],
   "source": [
    "s_train, s_test, encoder_train, encoder_test    , y_train, y_test= train_test_split(s, phi, y, \n",
    "                                                                                    test_size=0.1)\n",
    "print(s_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f01d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810, 2)\n"
     ]
    }
   ],
   "source": [
    "s_train_ensemble, s_train_mse, X_train_ensemble, X_train_mse, y_train_ensemble, y_train_mse= train_test_split(s_train, encoder_train, y_train, test_size=0.25)\n",
    "print(s_train_ensemble.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500402ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 2)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 155)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               15600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 51,052\n",
      "Trainable params: 51,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "8/8 - 1s - loss: 0.9981 - val_loss: 0.5391\n",
      "Epoch 2/400\n",
      "8/8 - 0s - loss: 0.3578 - val_loss: 0.2668\n",
      "Epoch 3/400\n",
      "8/8 - 0s - loss: 0.2136 - val_loss: 0.1423\n",
      "Epoch 4/400\n",
      "8/8 - 0s - loss: 0.1835 - val_loss: 0.1177\n",
      "Epoch 5/400\n",
      "8/8 - 0s - loss: 0.1466 - val_loss: 0.1276\n",
      "Epoch 6/400\n",
      "8/8 - 0s - loss: 0.1388 - val_loss: 0.1302\n",
      "Epoch 7/400\n",
      "8/8 - 0s - loss: 0.1009 - val_loss: 0.0766\n",
      "Epoch 8/400\n",
      "8/8 - 0s - loss: 0.0899 - val_loss: 0.0749\n",
      "Epoch 9/400\n",
      "8/8 - 0s - loss: 0.0989 - val_loss: 0.0829\n",
      "Epoch 10/400\n",
      "8/8 - 0s - loss: 0.0720 - val_loss: 0.0790\n",
      "Epoch 11/400\n",
      "8/8 - 0s - loss: 0.0593 - val_loss: 0.0580\n",
      "Epoch 12/400\n",
      "8/8 - 0s - loss: 0.0449 - val_loss: 0.0625\n",
      "Epoch 13/400\n",
      "8/8 - 0s - loss: 0.0410 - val_loss: 0.0523\n",
      "Epoch 14/400\n",
      "8/8 - 0s - loss: 0.0371 - val_loss: 0.0884\n",
      "Epoch 15/400\n",
      "8/8 - 0s - loss: 0.0577 - val_loss: 0.0751\n",
      "Epoch 16/400\n",
      "8/8 - 0s - loss: 0.0550 - val_loss: 0.1094\n",
      "Epoch 17/400\n",
      "8/8 - 0s - loss: 0.0404 - val_loss: 0.0612\n",
      "Epoch 18/400\n",
      "8/8 - 0s - loss: 0.0462 - val_loss: 0.0517\n",
      "Epoch 19/400\n",
      "8/8 - 0s - loss: 0.0425 - val_loss: 0.0865\n",
      "Epoch 20/400\n",
      "8/8 - 0s - loss: 0.0366 - val_loss: 0.0466\n",
      "Epoch 21/400\n",
      "8/8 - 0s - loss: 0.0318 - val_loss: 0.0757\n",
      "Epoch 22/400\n",
      "8/8 - 0s - loss: 0.0356 - val_loss: 0.0805\n",
      "Epoch 23/400\n",
      "8/8 - 0s - loss: 0.0482 - val_loss: 0.0615\n",
      "Epoch 24/400\n",
      "8/8 - 0s - loss: 0.0401 - val_loss: 0.0780\n",
      "Epoch 25/400\n",
      "8/8 - 0s - loss: 0.0379 - val_loss: 0.0840\n",
      "Epoch 26/400\n",
      "8/8 - 0s - loss: 0.0350 - val_loss: 0.0698\n",
      "Epoch 27/400\n",
      "8/8 - 0s - loss: 0.0377 - val_loss: 0.0627\n",
      "Epoch 28/400\n",
      "8/8 - 0s - loss: 0.0333 - val_loss: 0.0450\n",
      "Epoch 29/400\n",
      "8/8 - 0s - loss: 0.0314 - val_loss: 0.0821\n",
      "Epoch 30/400\n",
      "8/8 - 0s - loss: 0.0338 - val_loss: 0.0644\n",
      "Epoch 31/400\n",
      "8/8 - 0s - loss: 0.0272 - val_loss: 0.0575\n",
      "Epoch 32/400\n",
      "8/8 - 0s - loss: 0.0254 - val_loss: 0.0585\n",
      "Epoch 33/400\n",
      "8/8 - 0s - loss: 0.0272 - val_loss: 0.0838\n",
      "Epoch 34/400\n",
      "8/8 - 0s - loss: 0.0265 - val_loss: 0.0580\n",
      "Epoch 35/400\n",
      "8/8 - 0s - loss: 0.0270 - val_loss: 0.0671\n",
      "Epoch 36/400\n",
      "8/8 - 0s - loss: 0.0280 - val_loss: 0.0644\n",
      "Epoch 37/400\n",
      "8/8 - 0s - loss: 0.0374 - val_loss: 0.0624\n",
      "Epoch 38/400\n",
      "8/8 - 0s - loss: 0.0378 - val_loss: 0.0922\n",
      "Epoch 39/400\n",
      "8/8 - 0s - loss: 0.0324 - val_loss: 0.1059\n",
      "Epoch 40/400\n",
      "8/8 - 0s - loss: 0.0476 - val_loss: 0.0717\n",
      "Epoch 41/400\n",
      "8/8 - 0s - loss: 0.0335 - val_loss: 0.0614\n",
      "Epoch 42/400\n",
      "8/8 - 0s - loss: 0.0229 - val_loss: 0.0700\n",
      "Epoch 43/400\n",
      "8/8 - 0s - loss: 0.0237 - val_loss: 0.0706\n",
      "Epoch 44/400\n",
      "8/8 - 0s - loss: 0.0231 - val_loss: 0.0817\n",
      "Epoch 45/400\n",
      "8/8 - 0s - loss: 0.0264 - val_loss: 0.0869\n",
      "Epoch 46/400\n",
      "8/8 - 0s - loss: 0.0248 - val_loss: 0.0726\n",
      "Epoch 47/400\n",
      "8/8 - 0s - loss: 0.0192 - val_loss: 0.0687\n",
      "Epoch 48/400\n",
      "8/8 - 0s - loss: 0.0225 - val_loss: 0.1088\n",
      "Epoch 49/400\n",
      "8/8 - 0s - loss: 0.0203 - val_loss: 0.0433\n",
      "Epoch 50/400\n",
      "8/8 - 0s - loss: 0.0221 - val_loss: 0.0616\n",
      "Epoch 51/400\n",
      "8/8 - 0s - loss: 0.0255 - val_loss: 0.0990\n",
      "Epoch 52/400\n",
      "8/8 - 0s - loss: 0.0223 - val_loss: 0.0605\n",
      "Epoch 53/400\n",
      "8/8 - 0s - loss: 0.0259 - val_loss: 0.0512\n",
      "Epoch 54/400\n",
      "8/8 - 0s - loss: 0.0215 - val_loss: 0.0677\n",
      "Epoch 55/400\n",
      "8/8 - 0s - loss: 0.0194 - val_loss: 0.0998\n",
      "Epoch 56/400\n",
      "8/8 - 0s - loss: 0.0200 - val_loss: 0.0528\n",
      "Epoch 57/400\n",
      "8/8 - 0s - loss: 0.0190 - val_loss: 0.0512\n",
      "Epoch 58/400\n",
      "8/8 - 0s - loss: 0.0153 - val_loss: 0.0611\n",
      "Epoch 59/400\n",
      "8/8 - 0s - loss: 0.0137 - val_loss: 0.0689\n",
      "Epoch 60/400\n",
      "8/8 - 0s - loss: 0.0171 - val_loss: 0.0663\n",
      "Epoch 61/400\n",
      "8/8 - 0s - loss: 0.0140 - val_loss: 0.0675\n",
      "Epoch 62/400\n",
      "8/8 - 0s - loss: 0.0151 - val_loss: 0.0743\n",
      "Epoch 63/400\n",
      "8/8 - 0s - loss: 0.0162 - val_loss: 0.0483\n",
      "Epoch 64/400\n",
      "8/8 - 0s - loss: 0.0146 - val_loss: 0.0832\n",
      "Epoch 65/400\n",
      "8/8 - 0s - loss: 0.0136 - val_loss: 0.0546\n",
      "Epoch 66/400\n",
      "8/8 - 0s - loss: 0.0147 - val_loss: 0.0648\n",
      "Epoch 67/400\n",
      "8/8 - 0s - loss: 0.0133 - val_loss: 0.0807\n",
      "Epoch 68/400\n",
      "8/8 - 0s - loss: 0.0145 - val_loss: 0.0710\n",
      "Epoch 69/400\n",
      "8/8 - 0s - loss: 0.0161 - val_loss: 0.0865\n",
      "Epoch 70/400\n",
      "8/8 - 0s - loss: 0.0175 - val_loss: 0.0541\n",
      "Epoch 71/400\n",
      "8/8 - 0s - loss: 0.0136 - val_loss: 0.0640\n",
      "Epoch 72/400\n",
      "8/8 - 0s - loss: 0.0112 - val_loss: 0.0843\n",
      "Epoch 73/400\n",
      "8/8 - 0s - loss: 0.0130 - val_loss: 0.1023\n",
      "Epoch 74/400\n",
      "8/8 - 0s - loss: 0.0114 - val_loss: 0.0559\n",
      "Epoch 75/400\n",
      "8/8 - 0s - loss: 0.0105 - val_loss: 0.0976\n",
      "Epoch 76/400\n",
      "8/8 - 0s - loss: 0.0141 - val_loss: 0.0555\n",
      "Epoch 77/400\n",
      "8/8 - 0s - loss: 0.0124 - val_loss: 0.0594\n",
      "Epoch 78/400\n",
      "8/8 - 0s - loss: 0.0110 - val_loss: 0.0610\n",
      "Epoch 79/400\n",
      "8/8 - 0s - loss: 0.0144 - val_loss: 0.0749\n",
      "Epoch 80/400\n",
      "8/8 - 0s - loss: 0.0119 - val_loss: 0.0766\n",
      "Epoch 81/400\n",
      "8/8 - 0s - loss: 0.0093 - val_loss: 0.0792\n",
      "Epoch 82/400\n",
      "8/8 - 0s - loss: 0.0081 - val_loss: 0.0580\n",
      "Epoch 83/400\n",
      "8/8 - 0s - loss: 0.0094 - val_loss: 0.0767\n",
      "Epoch 84/400\n",
      "8/8 - 0s - loss: 0.0131 - val_loss: 0.1141\n",
      "Epoch 85/400\n",
      "8/8 - 0s - loss: 0.0165 - val_loss: 0.0558\n",
      "Epoch 86/400\n",
      "8/8 - 0s - loss: 0.0166 - val_loss: 0.0611\n",
      "Epoch 87/400\n",
      "8/8 - 0s - loss: 0.0127 - val_loss: 0.1240\n",
      "Epoch 88/400\n",
      "8/8 - 0s - loss: 0.0204 - val_loss: 0.0846\n",
      "Epoch 89/400\n",
      "8/8 - 0s - loss: 0.0147 - val_loss: 0.0653\n",
      "Epoch 90/400\n",
      "8/8 - 0s - loss: 0.0154 - val_loss: 0.1042\n",
      "Epoch 91/400\n",
      "8/8 - 0s - loss: 0.0117 - val_loss: 0.0924\n",
      "Epoch 92/400\n",
      "8/8 - 0s - loss: 0.0133 - val_loss: 0.1133\n",
      "Epoch 93/400\n",
      "8/8 - 0s - loss: 0.0134 - val_loss: 0.0777\n",
      "Epoch 94/400\n",
      "8/8 - 0s - loss: 0.0103 - val_loss: 0.0648\n",
      "Epoch 95/400\n",
      "8/8 - 0s - loss: 0.0106 - val_loss: 0.1006\n",
      "Epoch 96/400\n",
      "8/8 - 0s - loss: 0.0086 - val_loss: 0.0939\n",
      "Epoch 97/400\n",
      "8/8 - 0s - loss: 0.0081 - val_loss: 0.0756\n",
      "Epoch 98/400\n",
      "8/8 - 0s - loss: 0.0080 - val_loss: 0.0844\n",
      "Epoch 99/400\n",
      "8/8 - 0s - loss: 0.0076 - val_loss: 0.0900\n",
      "Epoch 100/400\n",
      "8/8 - 0s - loss: 0.0131 - val_loss: 0.0815\n",
      "Epoch 101/400\n",
      "8/8 - 0s - loss: 0.0192 - val_loss: 0.0799\n",
      "Epoch 102/400\n",
      "8/8 - 0s - loss: 0.0173 - val_loss: 0.0961\n",
      "Epoch 103/400\n",
      "8/8 - 0s - loss: 0.0228 - val_loss: 0.0622\n",
      "Epoch 104/400\n",
      "8/8 - 0s - loss: 0.0189 - val_loss: 0.0944\n",
      "Epoch 105/400\n",
      "8/8 - 0s - loss: 0.0245 - val_loss: 0.0747\n",
      "Epoch 106/400\n",
      "8/8 - 0s - loss: 0.0196 - val_loss: 0.0843\n",
      "Epoch 107/400\n",
      "8/8 - 0s - loss: 0.0142 - val_loss: 0.0752\n",
      "Epoch 108/400\n",
      "8/8 - 0s - loss: 0.0117 - val_loss: 0.0663\n",
      "Epoch 109/400\n",
      "8/8 - 0s - loss: 0.0148 - val_loss: 0.0916\n",
      "Epoch 110/400\n",
      "8/8 - 0s - loss: 0.0117 - val_loss: 0.1081\n",
      "Epoch 111/400\n",
      "8/8 - 0s - loss: 0.0109 - val_loss: 0.0467\n",
      "Epoch 112/400\n",
      "8/8 - 0s - loss: 0.0092 - val_loss: 0.0598\n",
      "Epoch 113/400\n",
      "8/8 - 0s - loss: 0.0076 - val_loss: 0.1428\n",
      "Epoch 114/400\n",
      "8/8 - 0s - loss: 0.0082 - val_loss: 0.0855\n",
      "Epoch 115/400\n",
      "8/8 - 0s - loss: 0.0068 - val_loss: 0.0542\n",
      "Epoch 116/400\n",
      "8/8 - 0s - loss: 0.0090 - val_loss: 0.0692\n",
      "Epoch 117/400\n",
      "8/8 - 0s - loss: 0.0072 - val_loss: 0.0646\n",
      "Epoch 118/400\n",
      "8/8 - 0s - loss: 0.0069 - val_loss: 0.0802\n",
      "Epoch 119/400\n",
      "8/8 - 0s - loss: 0.0095 - val_loss: 0.0629\n",
      "Epoch 120/400\n",
      "8/8 - 0s - loss: 0.0148 - val_loss: 0.0557\n",
      "Epoch 121/400\n",
      "8/8 - 0s - loss: 0.0129 - val_loss: 0.1127\n",
      "Epoch 122/400\n",
      "8/8 - 0s - loss: 0.0112 - val_loss: 0.0517\n",
      "Epoch 123/400\n",
      "8/8 - 0s - loss: 0.0081 - val_loss: 0.0894\n",
      "Epoch 124/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.0092 - val_loss: 0.0792\n",
      "Epoch 125/400\n",
      "8/8 - 0s - loss: 0.0097 - val_loss: 0.0818\n",
      "Epoch 126/400\n",
      "8/8 - 0s - loss: 0.0086 - val_loss: 0.0687\n",
      "Epoch 127/400\n",
      "8/8 - 0s - loss: 0.0097 - val_loss: 0.0707\n",
      "Epoch 128/400\n",
      "8/8 - 0s - loss: 0.0101 - val_loss: 0.0718\n",
      "Epoch 129/400\n",
      "8/8 - 0s - loss: 0.0113 - val_loss: 0.0762\n",
      "Epoch 130/400\n",
      "8/8 - 0s - loss: 0.0114 - val_loss: 0.1074\n",
      "Epoch 131/400\n",
      "8/8 - 0s - loss: 0.0085 - val_loss: 0.0584\n",
      "Epoch 132/400\n",
      "8/8 - 0s - loss: 0.0116 - val_loss: 0.0965\n",
      "Epoch 133/400\n",
      "8/8 - 0s - loss: 0.0120 - val_loss: 0.0735\n",
      "Epoch 134/400\n",
      "8/8 - 0s - loss: 0.0067 - val_loss: 0.1075\n",
      "Epoch 135/400\n",
      "8/8 - 0s - loss: 0.0070 - val_loss: 0.0660\n",
      "Epoch 136/400\n",
      "8/8 - 0s - loss: 0.0049 - val_loss: 0.0569\n",
      "Epoch 137/400\n",
      "8/8 - 0s - loss: 0.0041 - val_loss: 0.0885\n",
      "Epoch 138/400\n",
      "8/8 - 0s - loss: 0.0038 - val_loss: 0.0758\n",
      "Epoch 139/400\n",
      "8/8 - 0s - loss: 0.0034 - val_loss: 0.0590\n",
      "Epoch 140/400\n",
      "8/8 - 0s - loss: 0.0034 - val_loss: 0.0623\n",
      "Epoch 141/400\n",
      "8/8 - 0s - loss: 0.0032 - val_loss: 0.0750\n",
      "Epoch 142/400\n",
      "8/8 - 0s - loss: 0.0041 - val_loss: 0.0721\n",
      "Epoch 143/400\n",
      "8/8 - 0s - loss: 0.0032 - val_loss: 0.0561\n",
      "Epoch 144/400\n",
      "8/8 - 0s - loss: 0.0033 - val_loss: 0.0662\n",
      "Epoch 145/400\n",
      "8/8 - 0s - loss: 0.0027 - val_loss: 0.0658\n",
      "Epoch 146/400\n",
      "8/8 - 0s - loss: 0.0037 - val_loss: 0.0789\n",
      "Epoch 147/400\n",
      "8/8 - 0s - loss: 0.0036 - val_loss: 0.0625\n",
      "Epoch 148/400\n",
      "8/8 - 0s - loss: 0.0030 - val_loss: 0.0655\n",
      "Epoch 149/400\n",
      "8/8 - 0s - loss: 0.0030 - val_loss: 0.0654\n",
      "Epoch 150/400\n",
      "8/8 - 0s - loss: 0.0025 - val_loss: 0.0692\n",
      "Epoch 151/400\n",
      "8/8 - 0s - loss: 0.0027 - val_loss: 0.0672\n",
      "Epoch 152/400\n",
      "8/8 - 0s - loss: 0.0024 - val_loss: 0.0710\n",
      "Epoch 153/400\n",
      "8/8 - 0s - loss: 0.0026 - val_loss: 0.0660\n",
      "Epoch 154/400\n",
      "8/8 - 0s - loss: 0.0020 - val_loss: 0.0690\n",
      "Epoch 155/400\n",
      "8/8 - 0s - loss: 0.0025 - val_loss: 0.0629\n",
      "Epoch 156/400\n",
      "8/8 - 0s - loss: 0.0027 - val_loss: 0.0605\n",
      "Epoch 157/400\n",
      "8/8 - 0s - loss: 0.0038 - val_loss: 0.0692\n",
      "Epoch 158/400\n",
      "8/8 - 0s - loss: 0.0046 - val_loss: 0.0730\n",
      "Epoch 159/400\n",
      "8/8 - 0s - loss: 0.0047 - val_loss: 0.0760\n",
      "Epoch 160/400\n",
      "8/8 - 0s - loss: 0.0049 - val_loss: 0.0809\n",
      "Epoch 161/400\n",
      "8/8 - 0s - loss: 0.0059 - val_loss: 0.0659\n",
      "Epoch 162/400\n",
      "8/8 - 0s - loss: 0.0051 - val_loss: 0.0687\n",
      "Epoch 163/400\n",
      "8/8 - 0s - loss: 0.0049 - val_loss: 0.0845\n",
      "Epoch 164/400\n",
      "8/8 - 0s - loss: 0.0076 - val_loss: 0.0600\n",
      "Epoch 165/400\n",
      "8/8 - 0s - loss: 0.0116 - val_loss: 0.0663\n",
      "Epoch 166/400\n",
      "8/8 - 0s - loss: 0.0089 - val_loss: 0.0873\n",
      "Epoch 167/400\n",
      "8/8 - 0s - loss: 0.0124 - val_loss: 0.0536\n",
      "Epoch 168/400\n",
      "8/8 - 0s - loss: 0.0120 - val_loss: 0.0729\n",
      "Epoch 169/400\n",
      "8/8 - 0s - loss: 0.0145 - val_loss: 0.0624\n",
      "Epoch 170/400\n",
      "8/8 - 0s - loss: 0.0115 - val_loss: 0.1088\n",
      "Epoch 171/400\n",
      "8/8 - 0s - loss: 0.0087 - val_loss: 0.0446\n",
      "Epoch 172/400\n",
      "8/8 - 0s - loss: 0.0066 - val_loss: 0.0591\n",
      "Epoch 173/400\n",
      "8/8 - 0s - loss: 0.0064 - val_loss: 0.0613\n",
      "Epoch 174/400\n",
      "8/8 - 0s - loss: 0.0072 - val_loss: 0.0567\n",
      "Epoch 175/400\n",
      "8/8 - 0s - loss: 0.0055 - val_loss: 0.0772\n",
      "Epoch 176/400\n",
      "8/8 - 0s - loss: 0.0054 - val_loss: 0.0548\n",
      "Epoch 177/400\n",
      "8/8 - 0s - loss: 0.0049 - val_loss: 0.0685\n",
      "Epoch 178/400\n",
      "8/8 - 0s - loss: 0.0045 - val_loss: 0.0899\n",
      "Epoch 179/400\n",
      "8/8 - 0s - loss: 0.0046 - val_loss: 0.0667\n",
      "Epoch 180/400\n",
      "8/8 - 0s - loss: 0.0055 - val_loss: 0.0683\n",
      "Epoch 181/400\n",
      "8/8 - 0s - loss: 0.0042 - val_loss: 0.0822\n",
      "Epoch 182/400\n",
      "8/8 - 0s - loss: 0.0036 - val_loss: 0.0770\n",
      "Epoch 183/400\n",
      "8/8 - 0s - loss: 0.0035 - val_loss: 0.0531\n",
      "Epoch 184/400\n",
      "8/8 - 0s - loss: 0.0036 - val_loss: 0.0643\n",
      "Epoch 185/400\n",
      "8/8 - 0s - loss: 0.0034 - val_loss: 0.0683\n",
      "Epoch 186/400\n",
      "8/8 - 0s - loss: 0.0032 - val_loss: 0.0586\n",
      "Epoch 187/400\n",
      "8/8 - 0s - loss: 0.0045 - val_loss: 0.0796\n",
      "Epoch 188/400\n",
      "8/8 - 0s - loss: 0.0041 - val_loss: 0.0744\n",
      "Epoch 189/400\n",
      "8/8 - 0s - loss: 0.0027 - val_loss: 0.0660\n",
      "Epoch 190/400\n",
      "8/8 - 0s - loss: 0.0025 - val_loss: 0.0727\n",
      "Epoch 191/400\n",
      "8/8 - 0s - loss: 0.0021 - val_loss: 0.0689\n",
      "Epoch 192/400\n",
      "8/8 - 0s - loss: 0.0020 - val_loss: 0.0616\n",
      "Epoch 193/400\n",
      "8/8 - 0s - loss: 0.0021 - val_loss: 0.0634\n",
      "Epoch 194/400\n",
      "8/8 - 0s - loss: 0.0021 - val_loss: 0.0818\n",
      "Epoch 195/400\n",
      "8/8 - 0s - loss: 0.0024 - val_loss: 0.0659\n",
      "Epoch 196/400\n",
      "8/8 - 0s - loss: 0.0031 - val_loss: 0.0698\n",
      "Epoch 197/400\n",
      "8/8 - 0s - loss: 0.0020 - val_loss: 0.0717\n",
      "Epoch 198/400\n",
      "8/8 - 0s - loss: 0.0019 - val_loss: 0.0634\n",
      "Epoch 199/400\n",
      "8/8 - 0s - loss: 0.0017 - val_loss: 0.0757\n",
      "Epoch 200/400\n",
      "8/8 - 0s - loss: 0.0025 - val_loss: 0.0725\n",
      "Epoch 201/400\n",
      "8/8 - 0s - loss: 0.0045 - val_loss: 0.0644\n",
      "Epoch 202/400\n",
      "8/8 - 0s - loss: 0.0132 - val_loss: 0.0941\n",
      "Epoch 203/400\n",
      "8/8 - 0s - loss: 0.0183 - val_loss: 0.0705\n",
      "Epoch 204/400\n",
      "8/8 - 0s - loss: 0.0099 - val_loss: 0.0783\n",
      "Epoch 205/400\n",
      "8/8 - 0s - loss: 0.0120 - val_loss: 0.0790\n",
      "Epoch 206/400\n",
      "8/8 - 0s - loss: 0.0234 - val_loss: 0.0733\n",
      "Epoch 207/400\n",
      "8/8 - 0s - loss: 0.0366 - val_loss: 0.0918\n",
      "Epoch 208/400\n",
      "8/8 - 0s - loss: 0.0321 - val_loss: 0.0816\n",
      "Epoch 209/400\n",
      "8/8 - 0s - loss: 0.0615 - val_loss: 0.0530\n",
      "Epoch 210/400\n",
      "8/8 - 0s - loss: 0.0666 - val_loss: 0.1164\n",
      "Epoch 211/400\n",
      "8/8 - 0s - loss: 0.0487 - val_loss: 0.1006\n",
      "Epoch 212/400\n",
      "8/8 - 0s - loss: 0.0428 - val_loss: 0.0833\n",
      "Epoch 213/400\n",
      "8/8 - 0s - loss: 0.0421 - val_loss: 0.1070\n",
      "Epoch 214/400\n",
      "8/8 - 0s - loss: 0.0316 - val_loss: 0.0859\n",
      "Epoch 215/400\n",
      "8/8 - 0s - loss: 0.0261 - val_loss: 0.1465\n",
      "Epoch 216/400\n",
      "8/8 - 0s - loss: 0.0235 - val_loss: 0.0686\n",
      "Epoch 217/400\n",
      "8/8 - 0s - loss: 0.0232 - val_loss: 0.1060\n",
      "Epoch 218/400\n",
      "8/8 - 0s - loss: 0.0221 - val_loss: 0.0854\n",
      "Epoch 219/400\n",
      "8/8 - 0s - loss: 0.0162 - val_loss: 0.0920\n",
      "Epoch 220/400\n",
      "8/8 - 0s - loss: 0.0135 - val_loss: 0.0756\n",
      "Epoch 221/400\n",
      "8/8 - 0s - loss: 0.0150 - val_loss: 0.0751\n",
      "Epoch 222/400\n",
      "8/8 - 0s - loss: 0.0192 - val_loss: 0.0675\n",
      "Epoch 223/400\n",
      "8/8 - 0s - loss: 0.0194 - val_loss: 0.0799\n",
      "Epoch 224/400\n",
      "8/8 - 0s - loss: 0.0140 - val_loss: 0.0661\n",
      "Epoch 225/400\n",
      "8/8 - 0s - loss: 0.0071 - val_loss: 0.0711\n",
      "Epoch 226/400\n",
      "8/8 - 0s - loss: 0.0085 - val_loss: 0.0634\n",
      "Epoch 227/400\n",
      "8/8 - 0s - loss: 0.0092 - val_loss: 0.0694\n",
      "Epoch 228/400\n",
      "8/8 - 0s - loss: 0.0108 - val_loss: 0.0740\n",
      "Epoch 229/400\n",
      "8/8 - 0s - loss: 0.0103 - val_loss: 0.0556\n",
      "Epoch 230/400\n",
      "8/8 - 0s - loss: 0.0152 - val_loss: 0.0455\n",
      "Epoch 231/400\n",
      "8/8 - 0s - loss: 0.0165 - val_loss: 0.0675\n",
      "Epoch 232/400\n",
      "8/8 - 0s - loss: 0.0183 - val_loss: 0.0665\n",
      "Epoch 233/400\n",
      "8/8 - 0s - loss: 0.0239 - val_loss: 0.0957\n",
      "Epoch 234/400\n",
      "8/8 - 0s - loss: 0.0138 - val_loss: 0.0805\n",
      "Epoch 235/400\n",
      "8/8 - 0s - loss: 0.0117 - val_loss: 0.0885\n",
      "Epoch 236/400\n",
      "8/8 - 0s - loss: 0.0099 - val_loss: 0.0698\n",
      "Epoch 237/400\n",
      "8/8 - 0s - loss: 0.0067 - val_loss: 0.0801\n",
      "Epoch 238/400\n",
      "8/8 - 0s - loss: 0.0067 - val_loss: 0.1066\n",
      "Epoch 239/400\n",
      "8/8 - 0s - loss: 0.0064 - val_loss: 0.0650\n",
      "Epoch 240/400\n",
      "8/8 - 0s - loss: 0.0068 - val_loss: 0.0745\n",
      "Epoch 241/400\n",
      "8/8 - 0s - loss: 0.0085 - val_loss: 0.0845\n",
      "Epoch 242/400\n",
      "8/8 - 0s - loss: 0.0074 - val_loss: 0.0790\n",
      "Epoch 243/400\n",
      "8/8 - 0s - loss: 0.0059 - val_loss: 0.0719\n",
      "Epoch 244/400\n",
      "8/8 - 0s - loss: 0.0048 - val_loss: 0.0691\n",
      "Epoch 245/400\n",
      "8/8 - 0s - loss: 0.0041 - val_loss: 0.0828\n",
      "Epoch 246/400\n",
      "8/8 - 0s - loss: 0.0036 - val_loss: 0.0696\n",
      "Epoch 247/400\n",
      "8/8 - 0s - loss: 0.0049 - val_loss: 0.0649\n",
      "Epoch 248/400\n",
      "8/8 - 0s - loss: 0.0049 - val_loss: 0.0741\n",
      "Epoch 249/400\n",
      "8/8 - 0s - loss: 0.0042 - val_loss: 0.0654\n",
      "Epoch 250/400\n",
      "8/8 - 0s - loss: 0.0050 - val_loss: 0.1125\n",
      "Epoch 251/400\n",
      "8/8 - 0s - loss: 0.0055 - val_loss: 0.0807\n",
      "Epoch 252/400\n",
      "8/8 - 0s - loss: 0.0044 - val_loss: 0.0853\n",
      "Epoch 253/400\n",
      "8/8 - 0s - loss: 0.0035 - val_loss: 0.0802\n",
      "Epoch 254/400\n",
      "8/8 - 0s - loss: 0.0030 - val_loss: 0.0611\n",
      "Epoch 255/400\n",
      "8/8 - 0s - loss: 0.0037 - val_loss: 0.0876\n",
      "Epoch 256/400\n",
      "8/8 - 0s - loss: 0.0043 - val_loss: 0.0619\n",
      "Epoch 257/400\n",
      "8/8 - 0s - loss: 0.0034 - val_loss: 0.0578\n",
      "Epoch 258/400\n",
      "8/8 - 0s - loss: 0.0041 - val_loss: 0.0787\n",
      "Epoch 259/400\n",
      "8/8 - 0s - loss: 0.0044 - val_loss: 0.0892\n",
      "Epoch 260/400\n",
      "8/8 - 0s - loss: 0.0057 - val_loss: 0.0756\n",
      "Epoch 261/400\n",
      "8/8 - 0s - loss: 0.0060 - val_loss: 0.0707\n",
      "Epoch 262/400\n",
      "8/8 - 0s - loss: 0.0069 - val_loss: 0.0879\n",
      "Epoch 263/400\n",
      "8/8 - 0s - loss: 0.0083 - val_loss: 0.0463\n",
      "Epoch 264/400\n",
      "8/8 - 0s - loss: 0.0079 - val_loss: 0.0731\n",
      "Epoch 265/400\n",
      "8/8 - 0s - loss: 0.0080 - val_loss: 0.0846\n",
      "Epoch 266/400\n",
      "8/8 - 0s - loss: 0.0054 - val_loss: 0.1132\n",
      "Epoch 267/400\n",
      "8/8 - 0s - loss: 0.0063 - val_loss: 0.0459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/400\n",
      "8/8 - 0s - loss: 0.0045 - val_loss: 0.0587\n",
      "Epoch 269/400\n",
      "8/8 - 0s - loss: 0.0029 - val_loss: 0.0860\n",
      "Epoch 270/400\n",
      "8/8 - 0s - loss: 0.0031 - val_loss: 0.0679\n",
      "Epoch 271/400\n",
      "8/8 - 0s - loss: 0.0020 - val_loss: 0.0720\n",
      "Epoch 272/400\n",
      "8/8 - 0s - loss: 0.0017 - val_loss: 0.0675\n",
      "Epoch 273/400\n",
      "8/8 - 0s - loss: 0.0015 - val_loss: 0.0771\n",
      "Epoch 274/400\n",
      "8/8 - 0s - loss: 0.0013 - val_loss: 0.0857\n",
      "Epoch 275/400\n",
      "8/8 - 0s - loss: 0.0012 - val_loss: 0.0589\n",
      "Epoch 276/400\n",
      "8/8 - 0s - loss: 0.0015 - val_loss: 0.0755\n",
      "Epoch 277/400\n",
      "8/8 - 0s - loss: 0.0013 - val_loss: 0.0707\n",
      "Epoch 278/400\n",
      "8/8 - 0s - loss: 0.0011 - val_loss: 0.0692\n",
      "Epoch 279/400\n",
      "8/8 - 0s - loss: 0.0014 - val_loss: 0.0839\n",
      "Epoch 280/400\n",
      "8/8 - 0s - loss: 0.0013 - val_loss: 0.0632\n",
      "Epoch 281/400\n",
      "8/8 - 0s - loss: 0.0012 - val_loss: 0.0679\n",
      "Epoch 282/400\n",
      "8/8 - 0s - loss: 9.9240e-04 - val_loss: 0.0736\n",
      "Epoch 283/400\n",
      "8/8 - 0s - loss: 8.1983e-04 - val_loss: 0.0771\n",
      "Epoch 284/400\n",
      "8/8 - 0s - loss: 8.3353e-04 - val_loss: 0.0796\n",
      "Epoch 285/400\n",
      "8/8 - 0s - loss: 8.4703e-04 - val_loss: 0.0787\n",
      "Epoch 286/400\n",
      "8/8 - 0s - loss: 6.6703e-04 - val_loss: 0.0826\n",
      "Epoch 287/400\n",
      "8/8 - 0s - loss: 6.9598e-04 - val_loss: 0.0830\n",
      "Epoch 288/400\n",
      "8/8 - 0s - loss: 8.0672e-04 - val_loss: 0.0714\n",
      "Epoch 289/400\n",
      "8/8 - 0s - loss: 6.8129e-04 - val_loss: 0.0717\n",
      "Epoch 290/400\n",
      "8/8 - 0s - loss: 6.3382e-04 - val_loss: 0.0867\n",
      "Epoch 291/400\n",
      "8/8 - 0s - loss: 6.4511e-04 - val_loss: 0.0812\n",
      "Epoch 292/400\n",
      "8/8 - 0s - loss: 4.9283e-04 - val_loss: 0.0655\n",
      "Epoch 293/400\n",
      "8/8 - 0s - loss: 4.9755e-04 - val_loss: 0.0709\n",
      "Epoch 294/400\n",
      "8/8 - 0s - loss: 5.9271e-04 - val_loss: 0.0800\n",
      "Epoch 295/400\n",
      "8/8 - 0s - loss: 5.8402e-04 - val_loss: 0.0758\n",
      "Epoch 296/400\n",
      "8/8 - 0s - loss: 5.2619e-04 - val_loss: 0.0752\n",
      "Epoch 297/400\n",
      "8/8 - 0s - loss: 5.9409e-04 - val_loss: 0.0725\n",
      "Epoch 298/400\n",
      "8/8 - 0s - loss: 7.1063e-04 - val_loss: 0.0735\n",
      "Epoch 299/400\n",
      "8/8 - 0s - loss: 6.2132e-04 - val_loss: 0.0851\n",
      "Epoch 300/400\n",
      "8/8 - 0s - loss: 4.9644e-04 - val_loss: 0.0762\n",
      "Epoch 301/400\n",
      "8/8 - 0s - loss: 3.3836e-04 - val_loss: 0.0734\n",
      "Epoch 302/400\n",
      "8/8 - 0s - loss: 3.9615e-04 - val_loss: 0.0762\n",
      "Epoch 303/400\n",
      "8/8 - 0s - loss: 3.9070e-04 - val_loss: 0.0776\n",
      "Epoch 304/400\n",
      "8/8 - 0s - loss: 4.3449e-04 - val_loss: 0.0677\n",
      "Epoch 305/400\n",
      "8/8 - 0s - loss: 6.3291e-04 - val_loss: 0.0871\n",
      "Epoch 306/400\n",
      "8/8 - 0s - loss: 5.6772e-04 - val_loss: 0.0744\n",
      "Epoch 307/400\n",
      "8/8 - 0s - loss: 6.1808e-04 - val_loss: 0.0802\n",
      "Epoch 308/400\n",
      "8/8 - 0s - loss: 7.5898e-04 - val_loss: 0.0746\n",
      "Epoch 309/400\n",
      "8/8 - 0s - loss: 7.2555e-04 - val_loss: 0.0705\n",
      "Epoch 310/400\n",
      "8/8 - 0s - loss: 6.9748e-04 - val_loss: 0.0787\n",
      "Epoch 311/400\n",
      "8/8 - 0s - loss: 5.2335e-04 - val_loss: 0.0780\n",
      "Epoch 312/400\n",
      "8/8 - 0s - loss: 3.9178e-04 - val_loss: 0.0793\n",
      "Epoch 313/400\n",
      "8/8 - 0s - loss: 3.4808e-04 - val_loss: 0.0753\n",
      "Epoch 314/400\n",
      "8/8 - 0s - loss: 3.3093e-04 - val_loss: 0.0740\n",
      "Epoch 315/400\n",
      "8/8 - 0s - loss: 3.3080e-04 - val_loss: 0.0786\n",
      "Epoch 316/400\n",
      "8/8 - 0s - loss: 2.9027e-04 - val_loss: 0.0735\n",
      "Epoch 317/400\n",
      "8/8 - 0s - loss: 2.3085e-04 - val_loss: 0.0792\n",
      "Epoch 318/400\n",
      "8/8 - 0s - loss: 2.0831e-04 - val_loss: 0.0731\n",
      "Epoch 319/400\n",
      "8/8 - 0s - loss: 2.1951e-04 - val_loss: 0.0780\n",
      "Epoch 320/400\n",
      "8/8 - 0s - loss: 2.2934e-04 - val_loss: 0.0769\n",
      "Epoch 321/400\n",
      "8/8 - 0s - loss: 2.2014e-04 - val_loss: 0.0787\n",
      "Epoch 322/400\n",
      "8/8 - 0s - loss: 2.5515e-04 - val_loss: 0.0754\n",
      "Epoch 323/400\n",
      "8/8 - 0s - loss: 3.5329e-04 - val_loss: 0.0783\n",
      "Epoch 324/400\n",
      "8/8 - 0s - loss: 3.3845e-04 - val_loss: 0.0774\n",
      "Epoch 325/400\n",
      "8/8 - 0s - loss: 4.8927e-04 - val_loss: 0.0748\n",
      "Epoch 326/400\n",
      "8/8 - 0s - loss: 8.5087e-04 - val_loss: 0.0924\n",
      "Epoch 327/400\n",
      "8/8 - 0s - loss: 0.0017 - val_loss: 0.1064\n",
      "Epoch 328/400\n",
      "8/8 - 0s - loss: 0.0055 - val_loss: 0.1166\n",
      "Epoch 329/400\n",
      "8/8 - 0s - loss: 0.0076 - val_loss: 0.0964\n",
      "Epoch 330/400\n",
      "8/8 - 0s - loss: 0.0070 - val_loss: 0.0536\n",
      "Epoch 331/400\n",
      "8/8 - 0s - loss: 0.0096 - val_loss: 0.0839\n",
      "Epoch 332/400\n",
      "8/8 - 0s - loss: 0.0099 - val_loss: 0.0674\n",
      "Epoch 333/400\n",
      "8/8 - 0s - loss: 0.0069 - val_loss: 0.1047\n",
      "Epoch 334/400\n",
      "8/8 - 0s - loss: 0.0074 - val_loss: 0.0771\n",
      "Epoch 335/400\n",
      "8/8 - 0s - loss: 0.0076 - val_loss: 0.0545\n",
      "Epoch 336/400\n",
      "8/8 - 0s - loss: 0.0064 - val_loss: 0.0838\n",
      "Epoch 337/400\n",
      "8/8 - 0s - loss: 0.0059 - val_loss: 0.1044\n",
      "Epoch 338/400\n",
      "8/8 - 0s - loss: 0.0056 - val_loss: 0.0813\n",
      "Epoch 339/400\n",
      "8/8 - 0s - loss: 0.0055 - val_loss: 0.0788\n",
      "Epoch 340/400\n",
      "8/8 - 0s - loss: 0.0076 - val_loss: 0.0670\n",
      "Epoch 341/400\n",
      "8/8 - 0s - loss: 0.0054 - val_loss: 0.0664\n",
      "Epoch 342/400\n",
      "8/8 - 0s - loss: 0.0057 - val_loss: 0.1008\n",
      "Epoch 343/400\n",
      "8/8 - 0s - loss: 0.0070 - val_loss: 0.0786\n",
      "Epoch 344/400\n",
      "8/8 - 0s - loss: 0.0062 - val_loss: 0.0793\n",
      "Epoch 345/400\n",
      "8/8 - 0s - loss: 0.0051 - val_loss: 0.0680\n",
      "Epoch 346/400\n",
      "8/8 - 0s - loss: 0.0049 - val_loss: 0.0742\n",
      "Epoch 347/400\n",
      "8/8 - 0s - loss: 0.0079 - val_loss: 0.0758\n",
      "Epoch 348/400\n",
      "8/8 - 0s - loss: 0.0132 - val_loss: 0.0776\n",
      "Epoch 349/400\n",
      "8/8 - 0s - loss: 0.0130 - val_loss: 0.1147\n",
      "Epoch 350/400\n",
      "8/8 - 0s - loss: 0.0130 - val_loss: 0.0955\n",
      "Epoch 351/400\n",
      "8/8 - 0s - loss: 0.0148 - val_loss: 0.0846\n",
      "Epoch 352/400\n",
      "8/8 - 0s - loss: 0.0255 - val_loss: 0.1115\n",
      "Epoch 353/400\n",
      "8/8 - 0s - loss: 0.0262 - val_loss: 0.0943\n",
      "Epoch 354/400\n",
      "8/8 - 0s - loss: 0.0381 - val_loss: 0.0622\n",
      "Epoch 355/400\n",
      "8/8 - 0s - loss: 0.0268 - val_loss: 0.0666\n",
      "Epoch 356/400\n",
      "8/8 - 0s - loss: 0.0219 - val_loss: 0.0654\n",
      "Epoch 357/400\n",
      "8/8 - 0s - loss: 0.0236 - val_loss: 0.0592\n",
      "Epoch 358/400\n",
      "8/8 - 0s - loss: 0.0196 - val_loss: 0.0592\n",
      "Epoch 359/400\n",
      "8/8 - 0s - loss: 0.0150 - val_loss: 0.0688\n",
      "Epoch 360/400\n",
      "8/8 - 0s - loss: 0.0136 - val_loss: 0.1001\n",
      "Epoch 361/400\n",
      "8/8 - 0s - loss: 0.0090 - val_loss: 0.0808\n",
      "Epoch 362/400\n",
      "8/8 - 0s - loss: 0.0061 - val_loss: 0.0579\n",
      "Epoch 363/400\n",
      "8/8 - 0s - loss: 0.0085 - val_loss: 0.0907\n",
      "Epoch 364/400\n",
      "8/8 - 0s - loss: 0.0071 - val_loss: 0.0709\n",
      "Epoch 365/400\n",
      "8/8 - 0s - loss: 0.0088 - val_loss: 0.0716\n",
      "Epoch 366/400\n",
      "8/8 - 0s - loss: 0.0128 - val_loss: 0.0667\n",
      "Epoch 367/400\n",
      "8/8 - 0s - loss: 0.0103 - val_loss: 0.0741\n",
      "Epoch 368/400\n",
      "8/8 - 0s - loss: 0.0116 - val_loss: 0.1098\n",
      "Epoch 369/400\n",
      "8/8 - 0s - loss: 0.0091 - val_loss: 0.0511\n",
      "Epoch 370/400\n",
      "8/8 - 0s - loss: 0.0099 - val_loss: 0.0619\n",
      "Epoch 371/400\n",
      "8/8 - 0s - loss: 0.0097 - val_loss: 0.0722\n",
      "Epoch 372/400\n",
      "8/8 - 0s - loss: 0.0059 - val_loss: 0.1104\n",
      "Epoch 373/400\n",
      "8/8 - 0s - loss: 0.0052 - val_loss: 0.0576\n",
      "Epoch 374/400\n",
      "8/8 - 0s - loss: 0.0034 - val_loss: 0.0629\n",
      "Epoch 375/400\n",
      "8/8 - 0s - loss: 0.0037 - val_loss: 0.0738\n",
      "Epoch 376/400\n",
      "8/8 - 0s - loss: 0.0031 - val_loss: 0.0789\n",
      "Epoch 377/400\n",
      "8/8 - 0s - loss: 0.0037 - val_loss: 0.0740\n",
      "Epoch 378/400\n",
      "8/8 - 0s - loss: 0.0035 - val_loss: 0.0756\n",
      "Epoch 379/400\n",
      "8/8 - 0s - loss: 0.0025 - val_loss: 0.0705\n",
      "Epoch 380/400\n",
      "8/8 - 0s - loss: 0.0027 - val_loss: 0.0585\n",
      "Epoch 381/400\n",
      "8/8 - 0s - loss: 0.0030 - val_loss: 0.0649\n",
      "Epoch 382/400\n",
      "8/8 - 0s - loss: 0.0020 - val_loss: 0.0864\n",
      "Epoch 383/400\n",
      "8/8 - 0s - loss: 0.0015 - val_loss: 0.0666\n",
      "Epoch 384/400\n",
      "8/8 - 0s - loss: 0.0017 - val_loss: 0.0740\n",
      "Epoch 385/400\n",
      "8/8 - 0s - loss: 0.0024 - val_loss: 0.0837\n",
      "Epoch 386/400\n",
      "8/8 - 0s - loss: 0.0026 - val_loss: 0.0546\n",
      "Epoch 387/400\n",
      "8/8 - 0s - loss: 0.0020 - val_loss: 0.0694\n",
      "Epoch 388/400\n",
      "8/8 - 0s - loss: 0.0023 - val_loss: 0.0937\n",
      "Epoch 389/400\n",
      "8/8 - 0s - loss: 0.0013 - val_loss: 0.0791\n",
      "Epoch 390/400\n",
      "8/8 - 0s - loss: 9.1637e-04 - val_loss: 0.0725\n",
      "Epoch 391/400\n",
      "8/8 - 0s - loss: 6.8000e-04 - val_loss: 0.0754\n",
      "Epoch 392/400\n",
      "8/8 - 0s - loss: 6.5770e-04 - val_loss: 0.0698\n",
      "Epoch 393/400\n",
      "8/8 - 0s - loss: 6.2428e-04 - val_loss: 0.0737\n",
      "Epoch 394/400\n",
      "8/8 - 0s - loss: 7.7727e-04 - val_loss: 0.0756\n",
      "Epoch 395/400\n",
      "8/8 - 0s - loss: 6.5821e-04 - val_loss: 0.0733\n",
      "Epoch 396/400\n",
      "8/8 - 0s - loss: 8.0790e-04 - val_loss: 0.0726\n",
      "Epoch 397/400\n",
      "8/8 - 0s - loss: 8.2824e-04 - val_loss: 0.0731\n",
      "Epoch 398/400\n",
      "8/8 - 0s - loss: 0.0011 - val_loss: 0.0726\n",
      "Epoch 399/400\n",
      "8/8 - 0s - loss: 0.0042 - val_loss: 0.0828\n",
      "Epoch 400/400\n",
      "8/8 - 0s - loss: 0.0072 - val_loss: 0.0634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14583c0310a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_train_ensemble1, s_train_ensemble2, X_train_ensemble1, X_train_ensemble2, y_train_ensemble1, y_train_ensemble2= train_test_split(s_train_ensemble, X_train_ensemble, y_train_ensemble, test_size=0.3)\n",
    "print(s_train_ensemble1.shape)\n",
    "base_model = Model(inputs = input_dim, outputs = final_layer)\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "# Compile the Model\n",
    "base_model.compile(optimizer = optimizer, loss = 'mse')\n",
    "base_model.summary()\n",
    "base_model.fit(X_train_ensemble1, y_train_ensemble1,validation_split = 0.1, epochs = 400,\n",
    "                batch_size = 64,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969ac497",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = Model(inputs = input_dim, outputs = layer5)\n",
    "# base_model1.layers[-1].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87eb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred,y_true):\n",
    "    mse = np.mean((y_pred-y_true)**2)\n",
    "    return mse\n",
    "\n",
    "def mae(y_pred,y_true):\n",
    "    mae = np.mean(np.absolute(y_pred-y_true))\n",
    "    return mae\n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train,X_test,y_test):\n",
    "    # DeepKriging model for continuous data\n",
    "    ensemble_model = Sequential()\n",
    "\n",
    "    ensemble_model.add(base_model1)\n",
    "#     ensemble_model.add(Dense(50, activation = \"relu\"))\n",
    "    ensemble_model.add(Dense(50, activation = \"relu\"))\n",
    "    ensemble_model.add(Dense(2, activation='linear'))\n",
    "    ensemble_model.layers[-3].trainable = False\n",
    "    optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "    ensemble_model.compile(optimizer=optimizer, loss='mse', metrics=['mse','mae'])\n",
    "    ensemble_model.fit(X_train, y_train,#validation_data=(X_test,y_test), \n",
    "                       epochs = 200, batch_size = 64, verbose = 0)\n",
    "    return ensemble_model\n",
    "\n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, Y_train):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "#         x_train, x_test,y_train,y_test = train_test_split(X_train,Y_train,test_size = 0.1)\n",
    "        # define and fit the model on the training set\n",
    "        model = fit_model(X_train, Y_train,X_train,Y_train)\n",
    "        # evaluate model on the test set\n",
    "#         yhat = model.predict(x_test, verbose=0)\n",
    "#         mae1 = mae(yhat, y_test)\n",
    "#         print('>%d, MAE: %.3f' % (i+1, mae1))\n",
    "        # store the model\n",
    "        print(i)\n",
    "        ensemble.append(model)\n",
    "    return ensemble\n",
    "def y_list_uni(yhat,i):\n",
    "    the_list = list()\n",
    "    for j in range(len(yhat)):\n",
    "        the_list.append(yhat[j][0][i])\n",
    "    return the_list\n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def variance(data):\n",
    "    # Number of observations\n",
    "    n = len(data)\n",
    "    # Mean of the data\n",
    "    mean = sum(data) / n\n",
    "    # Square deviations\n",
    "    deviations = [(x - mean) ** 2 for x in data]\n",
    "    # Variance\n",
    "    variance = sum(deviations) / (n-1)\n",
    "    return variance\n",
    "def predict_with_pi(ensemble, X):\n",
    "    mean_vec1 = list()\n",
    "    mean_vec2 = list()\n",
    "    var_vec1 = list()\n",
    "    var_vec2 = list()\n",
    "    # make predictions\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    for data in tqdm(range(X.shape[0])):\n",
    "        yhat1 = np.asarray(np.asarray(yhat)[:,data,:])\n",
    "        var1_pred = yhat1[:,0]\n",
    "        var2_pred = yhat1[:,1]\n",
    "        mean1 = var1_pred.mean()\n",
    "        var1 = variance(var1_pred)\n",
    "        mean2 = var2_pred.mean()\n",
    "        var2 = variance(var2_pred)\n",
    "        mean_vec1.append(mean1)\n",
    "        mean_vec2.append(mean2)\n",
    "        var_vec1.append(var1)\n",
    "        var_vec2.append(var2)\n",
    "    return mean_vec1, var_vec1, mean_vec2, var_vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc232626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [00:00<00:00, 1316.27it/s]\n"
     ]
    }
   ],
   "source": [
    "n_members = 20\n",
    "ensemble = fit_ensemble(n_members, X_train_ensemble, y_train_ensemble)\n",
    "\n",
    "# train data mean and variance vectors\n",
    "mean_vec1, var_vec1, mean_vec2, var_vec2 = predict_with_pi(ensemble, X_train_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1ad99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random error calculation on training data\n",
    "r1 = list()\n",
    "r2 = list()\n",
    "r1 = (y_train_mse[:,0] - mean_vec1)**2 - var_vec1\n",
    "for i in range(len(r1)):\n",
    "    if r1[i] < 0: r1[i] = 0.0\n",
    "r2 = (y_train_mse[:,1] - mean_vec2)**2 - var_vec2\n",
    "for i in range(len(r2)):\n",
    "    if r2[i] < 0: r2[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00b5048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(s1,s2):\n",
    "    return(np.sqrt((s1[0] - s2[0])**2 + (s1[1] - s2[1])**2))\n",
    "\n",
    "def get_nearest_data(s_train,s_test,r,k):\n",
    "    dist_mat = np.zeros((len(s_test),len(s_train)))\n",
    "    nearest_var = np.zeros((len(s_test)))\n",
    "    for i in range(len(s_train)):\n",
    "        for j in range(len(s_test)):\n",
    "            dist_mat[j][i] = calc_distance(s_train[i],s_test[j])\n",
    "    for i in range(len(s_test)):\n",
    "        a = dist_mat[i]\n",
    "        b = np.argpartition(a,k)[:k]\n",
    "        y_val = []\n",
    "        for index in b:\n",
    "            y_val.append(r[index])\n",
    "        nearest_var[i] = (np.mean(y_val))\n",
    "    return nearest_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4cc519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 618.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%s seconds 798.0267617702484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# random error calculation on test data with neighbourhood approach\n",
    "r1_pred = get_nearest_data(s_train_mse,s_test,r1,40)\n",
    "r2_pred = get_nearest_data(s_train_mse,s_test,r2,40)\n",
    "\n",
    "# mean and variance vector for prediction data\n",
    "mean_vec1, var_vec1, mean_vec2, var_vec2 = predict_with_pi(ensemble, encoder_test)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"%s seconds\", end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abeec08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# e = list()\n",
    "# for i in range(len(r1_pred)):\n",
    "#     e.append(r1_pred[i][0])\n",
    "# print(len(var_vec1))\n",
    "# error_vec2 = model_mse2.predict(encoder_test)\n",
    "var_vec1 = np.asarray(var_vec1)\n",
    "var_vec2 = np.asarray(var_vec2)\n",
    "# e = np.asarray(e)\n",
    "lower_bound1 = mean_vec1 - 1.96*np.sqrt(var_vec1 + r1_pred)\n",
    "upper_bound1 = mean_vec1 + 1.96*np.sqrt(var_vec1 + r1_pred)\n",
    "lower_bound2 = mean_vec2 - 1.96*np.sqrt(var_vec2 + r2_pred)\n",
    "upper_bound2 = mean_vec2 + 1.96*np.sqrt(var_vec2 + r2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fd35c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_var0 = 0\n",
    "count_var1 = 0\n",
    "for i in range(len(y_test)):\n",
    "    if ((y_test[i,0] > lower_bound1[i]) and (y_test[i,0] < upper_bound1[i])): count_var0 +=1\n",
    "    if y_test[i,1] > lower_bound2[i] and y_test[i,1] < upper_bound2[i]: count_var1 +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8af7b51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9583333333333334,0.95\n"
     ]
    }
   ],
   "source": [
    "picp1 = count_var0/len(y_test)\n",
    "picp2 = count_var1/len(y_test)\n",
    "print(str(picp1)+\",\"+str(picp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad3e1066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0243789720870606,1.0793826950773922\n"
     ]
    }
   ],
   "source": [
    "width1 = np.mean(upper_bound1 - lower_bound1)\n",
    "width2 = np.mean(upper_bound2 - lower_bound2)\n",
    "print(str(width1)+\",\"+str(width2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36903c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bounds = pd.DataFrame(np.vstack((lower_bound1,upper_bound1,lower_bound2,upper_bound2)).T,\n",
    "                         columns = [\"l1\",\"u1\",\"l2\",\"u2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4128f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bounds.to_csv(\"../plot_results/bounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325fa41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
